<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Apache Camel K development inside Eclipse Che: Iteration 1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/sI5gl7fkbpk/" /><category term="Developer Tools" /><category term="Java" /><category term="VS Code" /><category term="Camel K" /><category term="Eclipse Che 7" /><category term="minikube" /><category term="Red Hat Integration" /><author><name>Aurélien Pupier</name></author><id>https://developers.redhat.com/blog/?p=669797</id><updated>2020-01-24T08:00:31Z</updated><published>2020-01-24T08:00:31Z</published><content type="html">&lt;p&gt;The Eclipse Che &lt;a href="https://github.com/eclipse/che/releases/tag/7.6.0" target="_blank" rel="noopener noreferrer"&gt;7.6.0 release&lt;/a&gt; provides a new stack for &lt;a href="https://camel.apache.org/camel-k/latest/index.html" target="_blank" rel="noopener noreferrer"&gt;Apache Camel K&lt;/a&gt; integration development. This release is the first iteration to give a preview of what is possible. If you like what you see, shout it out, and more will surely come.&lt;/p&gt; &lt;p&gt;This article details how to test this release on a local instance deployed on &lt;a href="https://minikube.sigs.k8s.io/" target="_blank" rel="noopener noreferrer"&gt;minikube&lt;/a&gt;. The difference with a hosted instance is that we avoid the prerequisites involving Camel K installation in the cluster and specific rights for the user.&lt;/p&gt; &lt;p&gt;&lt;span id="more-669797"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Set up the Che instance&lt;/h2&gt; &lt;p&gt;A container host needs to be available. For instance, you can use minikube. Che requires a large amount of memory, so you need to increase what is allocated by default. For instance:&lt;/p&gt; &lt;pre&gt;$ minikube start --memory=4096&lt;/pre&gt; &lt;p&gt;This command provides output like this:&lt;/p&gt; &lt;pre&gt;&amp;#x1f604; minikube v1.3.1 on Fedora 31 &amp;#x1f525; Creating virtualbox VM (CPUs=4, Memory=4096MB, Disk=50000MB) ... &amp;#x1f433; Preparing Kubernetes v1.15.2 on Docker 18.09.8 ... &amp;#x1f69c; Pulling images ... &amp;#x1f680; Launching Kubernetes ... &amp;#x231b; Waiting for: apiserver proxy etcd scheduler controller dns &amp;#x1f3c4; Done! kubectl is now configured to use "minikube" &lt;/pre&gt; &lt;p&gt;See the &lt;a href="https://www.eclipse.org/che/docs/che-7/running-che-locally/#using-minikube-to-set-up-kubernetes_running-che-locally" target="_blank" rel="noopener noreferrer"&gt;official Che 7 documentation&lt;/a&gt; for more details. Then, download &lt;code&gt;chectl&lt;/code&gt; from &lt;a href="https://github.com/che-incubator/chectl/releases" target="_blank" rel="noopener noreferrer"&gt;GitHub releases&lt;/a&gt;. You will be able to install Che on your minikube instance with the following command:&lt;/p&gt; &lt;pre&gt;$ chectl server:start --platform minikube&lt;/pre&gt; &lt;p&gt;This command provides output like this:&lt;/p&gt; &lt;pre&gt; &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Verify Kubernetes API...OK &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; &amp;#x1f440; Looking for an already existing Che instance &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Verify if Che is deployed into namespace "che"...it is not &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; &amp;#x2708; Minikube preflight checklist &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Verify if kubectl is installed &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Verify if minikube is installed &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Verify if minikube is running &lt;span style="color: #c4a000;"&gt;↓&lt;/span&gt; Start minikube [skipped] &lt;span style="color: #555753;"&gt; → Minikube is already running.&lt;/span&gt; &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Verify if minikube ingress addon is enabled &lt;span style="color: #c4a000;"&gt;↓&lt;/span&gt; Enable minikube ingress addon [skipped] &lt;span style="color: #555753;"&gt; → Ingress addon is already enabled.&lt;/span&gt; &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Retrieving minikube IP and domain for ingress URLs...192.168.99.123.nip.io. &lt;span style="color: #c4a000;"&gt;❯&lt;/span&gt; &amp;#x1f3c3;&amp;#x200d; Running Helm to install Che &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Verify if helm is installed &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Check Helm Version: Found v3.0.0+ge29ce2a &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Create Namespace (che)...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; &amp;#x1f3c3;&amp;#x200d; Running Helm to install Che &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Verify if helm is installed &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Check Helm Version: Found v3.0.0+ge29ce2a &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Create Namespace (che)...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Check Cluster Role Binding...does not exists. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Preparing Che Helm Chart...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Updating Helm Chart dependencies...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Deploying Che Helm Chart...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; &amp;#x2705; Post installation checklist &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Devfile registry pod bootstrap &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; scheduling...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; downloading images...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; starting...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Plugin registry pod bootstrap &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; scheduling...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; downloading images...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; starting...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Che pod bootstrap &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; scheduling...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; downloading images...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; starting...done. &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Retrieving Che Server URL...http://che-che.192.168.99.123.nip.io &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Che status check Command server:start has completed successfully. &lt;/pre&gt; &lt;p&gt;For more details and options, see the official Che 7 documentation.&lt;/p&gt; &lt;h2&gt;Create and configure a Camel K-ready workspace&lt;/h2&gt; &lt;p&gt;To create and configure your Camel K-ready workspace, you first need to create a workspace from the Camel K stack. At the end of the previous command&amp;#8217;s log, the URL to access the Che instance is provided after &amp;#8220;Retrieving Che Server URL&amp;#8230;&amp;#8221;&lt;/p&gt; &lt;p&gt;Open this URL in a browser. Select the &lt;strong&gt;Apache Camel K&lt;/strong&gt; stack and then click the &lt;strong&gt;Create &amp;#38; Open&lt;/strong&gt; button, which opens the page shown in Figure 1:&lt;/p&gt; &lt;div id="attachment_671547" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-671547" class="wp-image-671547 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-05-03-1024x559.png" alt="The Eclipse Che workspace creation page." width="640" height="349" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-05-03-1024x559.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-05-03-300x164.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-05-03-768x419.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-671547" class="wp-caption-text"&gt;Figure 1: Create your new Apache Camel K workspace in Eclipse Che.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Wait for the workspace to be ready. This process can take several minutes, depending on your internet connection&amp;#8217;s speed.&lt;/p&gt; &lt;p&gt;Next, you need to inject the kubeconfig login context into the Che workspace. For that, you can return to your host and call:&lt;/p&gt; &lt;pre&gt;$ chectl workspace:inject -k&lt;/pre&gt; &lt;p&gt;Ensure that the injection for &lt;code&gt;vscode-camelkXXX&lt;/code&gt; is a success. This command provides output like this:&lt;/p&gt; &lt;pre&gt; &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Verify if namespace che exists &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Verify if the workspaces is running &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; Injecting configurations &lt;span style="color: #c4a000;"&gt;↓&lt;/span&gt; injecting kubeconfig into container che-machine-execcc7 [skipped] &lt;span style="color: #555753;"&gt; → the container doesn't support file injection&lt;/span&gt; &lt;span style="color: #c4a000;"&gt;↓&lt;/span&gt; injecting kubeconfig into container theia-idenue [skipped] &lt;span style="color: #555753;"&gt; → kubeconfig already exists in the target container&lt;/span&gt; &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; injecting kubeconfig into container vscode-xmlcem...done. &lt;span style="color: #c4a000;"&gt;↓&lt;/span&gt; injecting kubeconfig into container vscode-apache-camelt7t [skipped] &lt;span style="color: #555753;"&gt; → kubeconfig already exists in the target container&lt;/span&gt; &lt;span style="color: #4e9a06;"&gt;&amp;#x2714;&lt;/span&gt; injecting kubeconfig into container vscode-camelkrbj...done.&lt;/pre&gt; &lt;p&gt;Now, install Camel K. In the right column, click &lt;strong&gt;My Workspace&lt;/strong&gt; to expand the panel. Then, expand the &lt;strong&gt;Plugins -&amp;#62; vscode-camelkXXX&lt;/strong&gt; tree. Click &lt;strong&gt;New terminal&lt;/strong&gt;, then type:&lt;/p&gt; &lt;pre&gt;$ kamel install&lt;/pre&gt; &lt;p&gt;The result is shown in Figure 2:&lt;/p&gt; &lt;div id="attachment_671557" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-671557" class="wp-image-671557 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-24-11-1024x703.png" alt="Eclipse Che showing your newly created terminal." width="640" height="439" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-24-11-1024x703.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-24-11-300x206.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-24-11-768x527.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-24-11.png 1094w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-671557" class="wp-caption-text"&gt;Figure 2: Create your new terminal inside your new workspace&amp;#8217;s &lt;strong&gt;Plugins&lt;/strong&gt;.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Deploy and automatically redeploy a Camel K integration&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://github.com/apache/camel-k/tree/master/examples" target="_blank" rel="noopener noreferrer"&gt;official Camel K examples&lt;/a&gt; are populated by default. You can open, for instance, &lt;code&gt;hello.xml&lt;/code&gt;&lt;em&gt;.&lt;/em&gt; Notice that the integration simply logs &amp;#8220;Hello World!!!&amp;#8221; every three seconds.&lt;/p&gt; &lt;p&gt;Right-click on this example in the &lt;strong&gt;Projects&lt;/strong&gt; panel. Select &lt;strong&gt;Start Apache Camel K integration&lt;/strong&gt; and then &lt;strong&gt;Dev mode &amp;#8211; Apache Camel integration in Dev mode&lt;/strong&gt;, as shown in Figure 3:&lt;/p&gt; &lt;div id="attachment_671567" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-671567" class="wp-image-671567 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/startInDevMode-1024x530.gif" alt="The sequence for deploying hello world." width="640" height="331" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/startInDevMode-1024x530.gif 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/startInDevMode-300x155.gif 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/startInDevMode-768x398.gif 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-671567" class="wp-caption-text"&gt;Figure 3: Deploy the Hello World example.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Wait several seconds (or minutes) for the first deployment. Again, how long this takes depends on your internet connection&amp;#8217;s speed.&lt;/p&gt; &lt;p&gt;When ready, go to the &lt;strong&gt;Output&lt;/strong&gt; panel. Select &lt;strong&gt;Apache Camel K&lt;/strong&gt; output, which should display &amp;#8220;Hello World!!!&amp;#8221; logged every three seconds, as shown in Figure 4:&lt;/p&gt; &lt;div id="attachment_671577" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-671577" class="wp-image-671577 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-37-37-1024x559.png" alt="Eclipse Che showing the Apache Camel K output log." width="640" height="349" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-37-37-1024x559.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-37-37-300x164.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-37-37-768x419.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-671577" class="wp-caption-text"&gt;Figure 4: View the output log.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Modify the &lt;code&gt;hello.xml&lt;/code&gt; file&amp;#8217;s content. For instance, you might change the constant to &amp;#8220;Hello World from Che!!!&amp;#8221; The integration is automatically redeployed in a few milliseconds, as you can see in Figure 5:&lt;/p&gt; &lt;div id="attachment_671587" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-671587" class="wp-image-671587 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-39-07-1024x559.png" alt="Eclipse Che showing the updated results" width="640" height="349" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-39-07-1024x559.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-39-07-300x164.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Screenshot-from-2020-01-02-14-39-07-768x419.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-671587" class="wp-caption-text"&gt;Figure 5: The output log now shows the updated results from the automatic redeployment.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Because the Che workspace reuses the VS Code extension, you can use all of the &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-camelk" target="_blank" rel="noopener noreferrer"&gt;Tooling for Apache Camel K VS Code extension&lt;/a&gt;&amp;#8216;s features. See our previous article on &lt;a href="https://developers.redhat.com/blog/2019/09/30/sending-a-telegram-with-apache-camel-k-and-visual-studio-code/"&gt;how to create an integration sending a Telegram&lt;/a&gt; to take this example further.&lt;/p&gt; &lt;h2&gt;Known limitations&lt;/h2&gt; &lt;p&gt;There are two major known limitations. The login for the Camel K instance needs to be redone on each workspace startup, and on a remote cluster, special rights need to be given so you can install and access the Camel K instance.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F24%2Fapache-camel-k-development-inside-eclipse-che-iteration-1%2F&amp;#38;linkname=Apache%20Camel%20K%20development%20inside%20Eclipse%20Che%3A%20Iteration%201" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F24%2Fapache-camel-k-development-inside-eclipse-che-iteration-1%2F&amp;#38;linkname=Apache%20Camel%20K%20development%20inside%20Eclipse%20Che%3A%20Iteration%201" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F24%2Fapache-camel-k-development-inside-eclipse-che-iteration-1%2F&amp;#38;linkname=Apache%20Camel%20K%20development%20inside%20Eclipse%20Che%3A%20Iteration%201" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F24%2Fapache-camel-k-development-inside-eclipse-che-iteration-1%2F&amp;#38;linkname=Apache%20Camel%20K%20development%20inside%20Eclipse%20Che%3A%20Iteration%201" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F24%2Fapache-camel-k-development-inside-eclipse-che-iteration-1%2F&amp;#38;linkname=Apache%20Camel%20K%20development%20inside%20Eclipse%20Che%3A%20Iteration%201" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F24%2Fapache-camel-k-development-inside-eclipse-che-iteration-1%2F&amp;#38;linkname=Apache%20Camel%20K%20development%20inside%20Eclipse%20Che%3A%20Iteration%201" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F24%2Fapache-camel-k-development-inside-eclipse-che-iteration-1%2F&amp;#38;linkname=Apache%20Camel%20K%20development%20inside%20Eclipse%20Che%3A%20Iteration%201" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F24%2Fapache-camel-k-development-inside-eclipse-che-iteration-1%2F&amp;#038;title=Apache%20Camel%20K%20development%20inside%20Eclipse%20Che%3A%20Iteration%201" data-a2a-url="https://developers.redhat.com/blog/2020/01/24/apache-camel-k-development-inside-eclipse-che-iteration-1/" data-a2a-title="Apache Camel K development inside Eclipse Che: Iteration 1"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/24/apache-camel-k-development-inside-eclipse-che-iteration-1/"&gt;Apache Camel K development inside Eclipse Che: Iteration 1&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/sI5gl7fkbpk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The Eclipse Che 7.6.0 release provides a new stack for Apache Camel K integration development. This release is the first iteration to give a preview of what is possible. If you like what you see, shout it out, and more will surely come. This article details how to test this release on a local instance deployed [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/24/apache-camel-k-development-inside-eclipse-che-iteration-1/"&gt;Apache Camel K development inside Eclipse Che: Iteration 1&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">669797</post-id><dc:creator>Aurélien Pupier</dc:creator><dc:date>2020-01-24T08:00:31Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/24/apache-camel-k-development-inside-eclipse-che-iteration-1/</feedburner:origLink></entry><entry><title>Editing, debugging, and GitHub in Red Hat CodeReady Workspaces 2</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/YljvUquRev0/" /><category term="Developer Tools" /><category term="Modern App Dev" /><category term="CodeReady Workspaces" /><category term="debugging" /><category term="github" /><category term="Golang" /><author><name>Don Schenck</name></author><id>https://developers.redhat.com/blog/?p=656177</id><updated>2020-01-23T20:19:35Z</updated><published>2020-01-23T20:19:35Z</published><content type="html">&lt;p&gt;In a previous article, I showed how to &lt;a href="https://developers.redhat.com/blog/?p=654277"&gt;get Red Hat CodeReady Workspaces 2.0 (CRW) up and running&lt;/a&gt; with a workspace available for use. This time, we will go through the edit-debug-push (to GitHub) cycle. This walk-through will simulate a real-life development effort.&lt;/p&gt; &lt;p&gt;To start, you&amp;#8217;ll need to fork a GitHub repository. The &lt;a href="https://github.com/redhat-developer-demos/qotd.git" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;Quote Of The Day&lt;/code&gt;&lt;/a&gt; repo contains a microservice written in Go that we&amp;#8217;ll use for this article. Don&amp;#8217;t worry if you&amp;#8217;ve never worked with Go. This is a simple program and we&amp;#8217;ll only change one line of code.&lt;/p&gt; &lt;p&gt;After you fork the repo, make note of (or copy) your fork&amp;#8217;s URL. We&amp;#8217;ll be using that information in a moment.&lt;/p&gt; &lt;p&gt;&lt;span id="more-656177"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Create a Go workspace&lt;/h2&gt; &lt;p&gt;Next, we&amp;#8217;ll use the pre-configured Go workspace as a basis to create our workspace in CRW. We will make a change to the configuration before we launch the workspace by removing the default demo GitHub reference and, instead, adding our forked repo&amp;#8217;s URL. Doing this means that our workspace will open with our code in front of us and ready for editing, debugging, and pushing back to our repo.&lt;/p&gt; &lt;p&gt;From the &lt;strong&gt;Workspaces&lt;/strong&gt; section, select the &lt;strong&gt;Add Workspace&lt;/strong&gt; button. When you are presented with the &lt;strong&gt;New Workspace&lt;/strong&gt; page, you will see a list of built-in workspaces. Select the &lt;strong&gt;Go&lt;/strong&gt; workspace. While you&amp;#8217;re on that page, also remove the &lt;strong&gt;example&lt;/strong&gt; project. Both actions are shown in Figure 1:&lt;/p&gt; &lt;div id="attachment_656377" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656377" class="wp-image-656377 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-1-1024x540.png" alt="Select the Go workspace and remove the example project." width="640" height="338" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-1-1024x540.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-1-300x158.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-1-768x405.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656377" class="wp-caption-text"&gt;Figure 1: Select the correct language workspace and remove the &lt;strong&gt;example&lt;/strong&gt; project.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The next step is to get the source code we want for this project. To do this, connect to your GitHub account by choosing the &lt;strong&gt;GitHub&lt;/strong&gt; option in the &lt;strong&gt;Add or import Project&lt;/strong&gt; section, as shown in Figure 2:&lt;/p&gt; &lt;div id="attachment_656397" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656397" class="wp-image-656397 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-3-1024x549.png" alt="Connect your GitHub account to a CRW workspace" width="640" height="343" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-3-1024x549.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-3-300x161.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-3-768x412.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656397" class="wp-caption-text"&gt;Figure 2: Connect your GitHub account to the new workspace.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After connecting, you will be presented with a list of every GitHub project to which you have rights. Note that the list is in alphabetical order by project.&lt;/p&gt; &lt;p&gt;Select the &lt;strong&gt;qotd&lt;/strong&gt; project—the one you forked earlier—and click the &lt;strong&gt;Add&lt;/strong&gt; button to add this project to your workspace definition, as shown in Figure 3:&lt;/p&gt; &lt;div id="attachment_656407" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656407" class="wp-image-656407 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-4-1024x529.png" alt="Select qotd and click Add" width="640" height="331" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-4-1024x529.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-4-300x155.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-4-768x397.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656407" class="wp-caption-text"&gt;Figure 3: Add the &lt;strong&gt;qotd&lt;/strong&gt; project to your workspace definition.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You should see a result similar to what&amp;#8217;s shown in Figure 4:&lt;/p&gt; &lt;div id="attachment_656417" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656417" class="wp-image-656417 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-5-1024x530.png" alt="Your new workspace definition" width="640" height="331" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-5-1024x530.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-5-300x155.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/new-go-workspace-5-768x397.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656417" class="wp-caption-text"&gt;Figure 4: Your new workspace definition.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When you reach this point, click the &lt;strong&gt;CREATE &amp;#38; OPEN&lt;/strong&gt; button (that huge green one) to get things rolling.&lt;/p&gt; &lt;p&gt;We have ignition. You&amp;#8217;ll notice something really cool at this point. CRW automagically opens the &lt;strong&gt;README.md&lt;/strong&gt; file in the editor, as shown in Figure 5:&lt;/p&gt; &lt;div id="attachment_656427" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656427" class="wp-image-656427 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/qotd-1-1024x388.png" alt="CRW editor with README.md displayed" width="640" height="243" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/qotd-1-1024x388.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/qotd-1-300x114.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/qotd-1-768x291.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/qotd-1.png 1035w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656427" class="wp-caption-text"&gt;Figure 5: The editor opens your project.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This is a small thing, but I think it&amp;#8217;s nice because it means that you start with an understanding of the project. Well played, &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;CodeReady Workspaces&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Explore the CRW IDE&lt;/h2&gt; &lt;p&gt;Before proceeding, let&amp;#8217;s label important parts of the IDE:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The file explorer, which is shown in Figure 5 in the previous section.&lt;/li&gt; &lt;li&gt;The &lt;strong&gt;Debug&lt;/strong&gt; section, which is shown in Figure 6.&lt;/li&gt; &lt;li&gt;The &lt;strong&gt;SOURCE CONTROL:GIT&lt;/strong&gt; section, which is shown in Figure 7:&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_656457" style="width: 412px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656457" class="wp-image-656457 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/debug-open.png" alt="The CRW Debug section." width="402" height="790" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/debug-open.png 402w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/debug-open-153x300.png 153w" sizes="(max-width: 402px) 100vw, 402px" /&gt;&lt;p id="caption-attachment-656457" class="wp-caption-text"&gt;Figure 6: The CRW &lt;strong&gt;Debug&lt;/strong&gt; section.&lt;/p&gt;&lt;/div&gt; &lt;div id="attachment_656467" style="width: 412px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656467" class="wp-image-656467 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/source-control-open.png" alt="The CRW Source Control (GitHub) section." width="402" height="296" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/source-control-open.png 402w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/source-control-open-300x221.png 300w" sizes="(max-width: 402px) 100vw, 402px" /&gt;&lt;p id="caption-attachment-656467" class="wp-caption-text"&gt;Figure 7: The CRW Source Control (GitHub) section.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;A single click on a file in the file explorer enables editing. In our case, we will wait on the editing until later in this article. For now, let&amp;#8217;s run the program, which brings up an interesting point: debugging.&lt;/p&gt; &lt;h2&gt;Debug your code&lt;/h2&gt; &lt;p&gt;To debug our code, we first need to set up a debugging configuration and then set a breakpoint. After all, you (I mean, &lt;em&gt;your colleague&lt;/em&gt;) might have introduced an error. Start by selecting &lt;strong&gt;View&lt;/strong&gt; -&amp;#62; &lt;strong&gt;Debug Console&lt;/strong&gt; from the menu bar at the top. Doing this will allow us to see messages as debugging starts. While being able to see this information is not necessary, it is nice to have.&lt;/p&gt; &lt;p&gt;Next, click on the &lt;strong&gt;Debug&lt;/strong&gt; icon on the left to access the &lt;strong&gt;Debug&lt;/strong&gt; section. At the top of the section, open the configuration drop-down. It initially reads &lt;strong&gt;No Configurations&lt;/strong&gt; but we&amp;#8217;re going to change that setting. Select &lt;strong&gt;Add Configuration&lt;/strong&gt; and then the &lt;strong&gt;Go: Launch package &lt;/strong&gt;option. The file &lt;strong&gt;launch.json&lt;/strong&gt; will be presented in the IDE.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; If the &lt;strong&gt;Go: Launch project&lt;/strong&gt; option does not appear, it&amp;#8217;s probably because you selected the wrong stack when you created the workspace. Don&amp;#8217;t ask how I know this.&lt;/p&gt; &lt;p&gt;Change the line that reads &lt;code&gt;"program": "${workspaceFolder}"&lt;/code&gt; to &lt;code&gt;"program": "${current.project.path}/main.go"&lt;/code&gt;, as shown in Figure 9:&lt;/p&gt; &lt;div id="attachment_656487" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656487" class="wp-image-656487 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/go-launch-package-300x38.png" alt="Edit the launch file to add a project debug configuration." width="300" height="38" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/go-launch-package-300x38.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/go-launch-package.png 658w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-656487" class="wp-caption-text"&gt;Figure 9: Edit the launch file to add a project debug configuration.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Click on the &lt;strong&gt;File Explorer&lt;/strong&gt; icon on the left and open the &lt;strong&gt;main.go&lt;/strong&gt; file. Click in the margin to the right of line number 16 to set a breakpoint, as shown in Figure 10:&lt;/p&gt; &lt;div id="attachment_656347" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-656347" class="wp-image-656347 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/breakpoint-set-1024x554.png" alt="Set your breakpoint in the File Explorer." width="640" height="346" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/breakpoint-set-1024x554.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/breakpoint-set-300x162.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/breakpoint-set-768x416.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/breakpoint-set.png 1417w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-656347" class="wp-caption-text"&gt;Figure 10: Set your breakpoint.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Start the engine&lt;/h2&gt; &lt;p&gt;Now, finally, we are ready to run our code. Click on the &lt;strong&gt;Debug&lt;/strong&gt; icon and then click the green right-facing arrow by the configuration drop-down to start the program in Debug mode. Or, just press &lt;strong&gt;F5&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;When the application starts, you will get messages related to the port number and the service&amp;#8217;s URL. Select the option offered in each prompt. A small browser window will open in the IDE. If you receive an error stating that the application is not ready, simply refresh the browser until the application starts to run. Note that you can click the small icon to launch your default browser outside of the IDE.&lt;/p&gt; &lt;p&gt;You will see your breakpoint highlighted. Feel free to poke around the debug values to the left, including local variables. When ready, click the &lt;strong&gt;Continue&lt;/strong&gt; button (blue arrow) in the debug control area.&lt;/p&gt; &lt;p&gt;When finished debugging, press the &lt;strong&gt;Stop&lt;/strong&gt; button (red box) in the debug control area.&lt;/p&gt; &lt;p&gt;Go ahead and change a quote in the program, then run in Debug mode again. When you are satisfied that your change works, we&amp;#8217;re ready to update our repo. For a developer, this feels like home. Edit, run, debug, edit, run, debug, etc. Press &lt;strong&gt;F11&lt;/strong&gt; at any time to run your browser in full-screen mode and you&amp;#8217;ll soon forget that you&amp;#8217;re using the web.&lt;/p&gt; &lt;h2&gt;Commit your code&lt;/h2&gt; &lt;p&gt;Click on the &lt;strong&gt;Source Control&lt;/strong&gt; icon to view the &lt;strong&gt;Source Control&lt;/strong&gt; area. In the message area, enter text to describe the change you just made. This information is used by the &lt;code&gt;git commit -m&lt;/code&gt; command. Then, click the commit checkbox above the message area. This is the &lt;code&gt;git commit&lt;/code&gt; command, and it uses the text you entered in the message area.&lt;/p&gt; &lt;h2&gt;Push back&lt;/h2&gt; &lt;p&gt;Now to fulfill the cycle and push our changes to our GitHub repo. Remember: We&amp;#8217;re working in a browser, so there is no &lt;strong&gt;File&lt;/strong&gt; -&amp;#62; &lt;strong&gt;Save&lt;/strong&gt; option.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; But there &lt;em&gt;could&lt;/em&gt; be. We have been doing everything in Ephemeral Mode (as noted at the bottom of your IDE), but CRW does support saving files to storage if you configured a Persistent Volume. That&amp;#8217;s another article for another time.&lt;/p&gt; &lt;p&gt;Select the ellipses (&lt;strong&gt;&amp;#8230;&lt;/strong&gt;) in the source control area and choose the &lt;strong&gt;Push&lt;/strong&gt; option. This action will prompt you for your GitHub username and password. After you have supplied these correctly, the code will be pushed to GitHub to update your repo.&lt;/p&gt; &lt;p&gt;Hop over to your browser and navigate to the GitHub repo, where you&amp;#8217;ll see your changes. You did it. You pulled down code, edited it, debugged it, and pushed it back to GitHub. And of course, you have a GitHub webhook configured to automatically kick off your CI/CD pipeline now, right?&lt;/p&gt; &lt;p&gt;Right?&lt;/p&gt; &lt;p&gt;That question looks like YABP—Yet Another Blog Post—is in order: GitHub to CI/CD using OpenShift Pipelines.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you shut down your workspace and then, later, start it again, it will pull down the current code. In other words, if someone else made changes during the interim, you&amp;#8217;ll see them. It&amp;#8217;s a small feature, but it&amp;#8217;s nice to have an automatic &lt;code&gt;git pull&lt;/code&gt; before you start work.&lt;/p&gt; &lt;h2&gt;What&amp;#8217;s next?&lt;/h2&gt; &lt;p&gt;I briefly mentioned a &lt;em&gt;stack&lt;/em&gt;. In the third and final article of this three-part series, I&amp;#8217;ll show you how to build a custom stack, which is a way to customize workspaces to your specific needs.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fediting-debugging-and-github-in-red-hat-codeready-workspaces-2%2F&amp;#38;linkname=Editing%2C%20debugging%2C%20and%20GitHub%20in%20Red%20Hat%20CodeReady%20Workspaces%202" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fediting-debugging-and-github-in-red-hat-codeready-workspaces-2%2F&amp;#38;linkname=Editing%2C%20debugging%2C%20and%20GitHub%20in%20Red%20Hat%20CodeReady%20Workspaces%202" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fediting-debugging-and-github-in-red-hat-codeready-workspaces-2%2F&amp;#38;linkname=Editing%2C%20debugging%2C%20and%20GitHub%20in%20Red%20Hat%20CodeReady%20Workspaces%202" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fediting-debugging-and-github-in-red-hat-codeready-workspaces-2%2F&amp;#38;linkname=Editing%2C%20debugging%2C%20and%20GitHub%20in%20Red%20Hat%20CodeReady%20Workspaces%202" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fediting-debugging-and-github-in-red-hat-codeready-workspaces-2%2F&amp;#38;linkname=Editing%2C%20debugging%2C%20and%20GitHub%20in%20Red%20Hat%20CodeReady%20Workspaces%202" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fediting-debugging-and-github-in-red-hat-codeready-workspaces-2%2F&amp;#38;linkname=Editing%2C%20debugging%2C%20and%20GitHub%20in%20Red%20Hat%20CodeReady%20Workspaces%202" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fediting-debugging-and-github-in-red-hat-codeready-workspaces-2%2F&amp;#38;linkname=Editing%2C%20debugging%2C%20and%20GitHub%20in%20Red%20Hat%20CodeReady%20Workspaces%202" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fediting-debugging-and-github-in-red-hat-codeready-workspaces-2%2F&amp;#038;title=Editing%2C%20debugging%2C%20and%20GitHub%20in%20Red%20Hat%20CodeReady%20Workspaces%202" data-a2a-url="https://developers.redhat.com/blog/2020/01/23/editing-debugging-and-github-in-red-hat-codeready-workspaces-2/" data-a2a-title="Editing, debugging, and GitHub in Red Hat CodeReady Workspaces 2"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/23/editing-debugging-and-github-in-red-hat-codeready-workspaces-2/"&gt;Editing, debugging, and GitHub in Red Hat CodeReady Workspaces 2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/YljvUquRev0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In a previous article, I showed how to get Red Hat CodeReady Workspaces 2.0 (CRW) up and running with a workspace available for use. This time, we will go through the edit-debug-push (to GitHub) cycle. This walk-through will simulate a real-life development effort. To start, you&amp;#8217;ll need to fork a GitHub repository. The Quote Of [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/23/editing-debugging-and-github-in-red-hat-codeready-workspaces-2/"&gt;Editing, debugging, and GitHub in Red Hat CodeReady Workspaces 2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">656177</post-id><dc:creator>Don Schenck</dc:creator><dc:date>2020-01-23T20:19:35Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/23/editing-debugging-and-github-in-red-hat-codeready-workspaces-2/</feedburner:origLink></entry><entry><title>This Week in JBoss: January 23, 2020</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/GRu9hc7P2vQ/this-week-in-jboss-january-23-2020" /><category term="byteman" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="ide" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="jbossws" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><category term="wildfly 19" scheme="searchisko:content:tags" /><author><name>Donald Naro</name></author><id>searchisko:content:id:jbossorg_blog-this_week_in_jboss_january_23_2020</id><updated>2020-01-23T12:11:01Z</updated><published>2020-01-23T12:11:01Z</published><content type="html">&lt;!-- [DocumentBodyStart:41ac270d-7f1a-4ea3-8e3b-796a50f65be8] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;Welcome to my first ever edition of the JBoss editorial. I'm pretty excited to be sharing news from the JBoss community and look forward to bringing you highlights and latest developments. Let's go!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Did someone say MicroProfile?&lt;/h2&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="https://microprofile.io/" rel="nofollow"&gt;Eclipse MicroProfile&lt;/a&gt; provide specifications for Enterprise Java microservices and this week we bring you news of two recent announcements&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;WildFly 19.0.0.Beta1, which is available since last week, includes implementations of all of the MicroProfile 3.2 specifications. It's an important achievement for the WildFly team and Brian Stansberry provides all the details and shouts out in his &lt;a class="jive-link-external-small" href="https://wildfly.org/news/2020/01/17/WildFly19-Beta-Released/" rel="nofollow"&gt;MicroProfile 3.2 in WildFly 19.0.0.Beta1&lt;/a&gt; announcement.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Quarkus as well recently &lt;a class="jive-link-external-small" href="https://quarkus.io/blog/quarkus-eclipse-microprofile-3-2-compatible/" rel="nofollow"&gt;announced compatibility with MicroProfile 3.2&lt;/a&gt;, another milestone for the project right on the heels of the 1.1.0.Final release.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Quarkus Tooling and RealWorld Demo&lt;/h2&gt;&lt;p&gt;Looking for dedicated Quarkus integration in your IDE? Check out the cleverly titled&amp;#160; on the &lt;a class="jive-link-external-small" href="https://quarkus.io/blog/march-of-ides/" rel="nofollow"&gt;March of IDEs post&lt;/a&gt; Quarkus blog.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;span&gt;If you're a fan of the RealWorld specification for fullstack app demos, then have a look at Diego Camara's &lt;a class="jive-link-external-small" href="https://github.com/diegocamara/realworld-api-quarkus" rel="nofollow"&gt;Quarkus example app&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Developer Articles and How To's&lt;/h2&gt;&lt;p&gt;S&amp;eacute;bastien Blanc shows us how to use &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2020/01/23/using-kubernetes-configmaps-to-define-your-quarkus-applications-properties/" rel="nofollow"&gt;ConfigMaps to define properties for Quarkus applications on Kubernetes&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;William Henry also breaks down &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/" rel="nofollow"&gt;Podman and Buildah for Docker users and shows how to migrate&lt;/a&gt;, answering lots of technical questions on the way.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Evangelist's Corner&lt;/h2&gt;&lt;p&gt;&lt;span&gt;JBoss evangelists release new demos and content to help people discover and use the latest version of the JBoss Community projects. Since the last editorial, Eric D. Schabell released an article that explains how to get a fully installed and configured Red Hat Decision Manager on your local machine. Learn &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/how_to_install_red_hat_decision_manager_7_5_in_minutes" rel="nofollow"&gt;how to install Red Hat Decision Maker in 7.5 minutes&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Releases&lt;/h2&gt;&lt;p&gt;Apart from WildFly 19.0.0Beta1 that we've already mentioned, here is a roundup of all the latest releases:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;a class="jive-link-external-small" href="https://byteman.jboss.org/downloads.html" rel="nofollow"&gt;Byteman 4.0.10&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a class="jive-link-external-small" href="http://jbossws.blogspot.com/2020/01/jbossws-540final-is-released.html" rel="nofollow"&gt;JBoss Web Services 5.4.0.Final&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;That's all for this edition of the Editorial, please join us next time as we continue our journey through JBoss Communities in search of interesting articles and news.&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:41ac270d-7f1a-4ea3-8e3b-796a50f65be8] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/GRu9hc7P2vQ" height="1" width="1" alt=""/&gt;</content><summary>Welcome to my first ever edition of the JBoss editorial. I'm pretty excited to be sharing news from the JBoss community and look forward to bringing you highlights and latest developments. Let's go!   Did someone say MicroProfile? Eclipse MicroProfile provide specifications for Enterprise Java microservices and this week we bring you news of two recent announcements   WildFly 19.0.0.Beta1, which i...</summary><dc:creator>Donald Naro</dc:creator><dc:date>2020-01-23T12:11:01Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2020/01/23/this-week-in-jboss-january-23-2020</feedburner:origLink></entry><entry><title>How to maintain stable build and deployment performance on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-_hIb6PgPQU/" /><category term="CI/CD" /><category term="Containers" /><category term="Kubernetes" /><category term="DevOps" /><category term="performance tuning" /><category term="Red Hat OpenShift" /><author><name>Daein Park</name></author><id>https://developers.redhat.com/blog/?p=666597</id><updated>2020-01-23T08:00:14Z</updated><published>2020-01-23T08:00:14Z</published><content type="html">&lt;p&gt;In this article, I will introduce helpful, common tips for managing reliable builds and deployments on &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;. If you have experienced a sudden performance degradation for builds and deployments on OpenShift, it might be helpful to troubleshoot your cluster. We will start by reviewing the whole process, from build to deployment, and then cover each aspect in more detail. We will use Red Hat OpenShift 4.2 (Kubernetes 1.14) for this purpose.&lt;span id="more-666597"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Processes from build to deployment&lt;/h2&gt; &lt;p&gt;When a CI/CD process or a user triggers the build for a pod deployment, the processes will proceed as shown in Figure 1, which is simplified for readability:&lt;/p&gt; &lt;div id="attachment_666617" style="width: 610px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-666617" class="wp-image-666617" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/build_deploy_performance-300x194.png" alt="The process workflow from building to deploying a pod." width="600" height="388" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/build_deploy_performance-300x194.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/build_deploy_performance-768x497.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/build_deploy_performance.png 821w" sizes="(max-width: 600px) 100vw, 600px" /&gt;&lt;p id="caption-attachment-666617" class="wp-caption-text"&gt;Figure 1: The process workflow from building to deploying a pod.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As you can see, Kubernetes does not control all of these processes, but the main processes for build and deployment depend on the user’s application build configuration and the dependencies on external systems. We can split out each process by which component has responsibility for managing things as shown in Figure 2:&lt;/p&gt; &lt;div id="attachment_666637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-666637" class="wp-image-666637 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/components_table-1024x258.png" alt="Build deployment process" width="640" height="161" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/components_table-1024x258.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/components_table-300x76.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/components_table-768x194.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/components_table.png 1412w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-666637" class="wp-caption-text"&gt;Figure 2: The build deployment process.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Kubernetes&lt;/h3&gt; &lt;p&gt;In this process, Kubernetes provides resources based on the &lt;code&gt;BuildConfig&lt;/code&gt; and &lt;code&gt;DeploymentConfig&lt;/code&gt; files. Usually, a build and deploy will fail before starting their work if there is any trouble handling resources, such as volume mount failure, scheduling pending, and so on. You can usually find the reasons for these failures easily in the event logs.&lt;/p&gt; &lt;p&gt;So, if both the build and deployment are successful—even though they took longer—this is not a Kubernetes scheduling and control problem. For clarifying the performance issue, we should ensure that &lt;code&gt;BuildConfig&lt;/code&gt; and &lt;code&gt;DeploymentConfig&lt;/code&gt; are configured with enough resource requests as in the following examples.&lt;/p&gt; &lt;p&gt;Here is a quick sample &lt;code&gt;BuildConfig&lt;/code&gt; for this scenario:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: BuildConfig metadata: name: sample-build spec: resources: requests: cpu: 500m memory: 256Mi &lt;/pre&gt; &lt;p&gt;Here is a quick sample &lt;code&gt;DeploymentConfig&lt;/code&gt; for this scenario:&lt;/p&gt; &lt;pre&gt;apiVersion: apps.openshift.io/v1 kind: DeploymentConfig metadata: name: sample-deployment spec: template: spec: containers: - image: test-image name: container1 resources: requests: cpu: 100m memory: 200Mi &lt;/pre&gt; &lt;p&gt;In general, you should allocate resources large enough to build and deploy reliably after testing, keeping in mind that this is not a minimum resource setting. For instance, if you set &lt;code&gt;resources.requests.cpu: 32m&lt;/code&gt;, Kubernetes will assign more CPU time through the &lt;code&gt;cpu.shares&lt;/code&gt; control group parameter as follows:&lt;/p&gt; &lt;pre&gt;# oc describe pod test-1-abcde | grep -E 'Node:|Container ID:|cpu:' Node: worker-0.ocp.example.local/x.x.x.x Container ID: cri-o://XXX... Container ID ...XXX cpu: 32m # oc get pod test-5-8z5lq -o yaml | grep -E '^ uid:' uid: YYYYYYYY-YYYY-YYYY-YYYY-YYYYYYYYYYYY worker-0 ~# cat \ /sys/fs/cgroup/cpu,cpuacct/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podYYYYYYYY_YYYY_YYYY_YYYY_YYYYYYYYYYYY.slice/crio-XXX... Container ID ...XXX.scope/cpu.shares 32 &lt;/pre&gt; &lt;p&gt;As of OpenShift 4.1, you can manage cluster-wide build defaults including the above resource requests through the &lt;code&gt;Build&lt;/code&gt; resource. Refer to &lt;a href="https://docs.openshift.com/container-platform/4.2/builds/build-configuration.html" target="_blank" rel="noopener noreferrer"&gt;Build configuration resources&lt;/a&gt; for more details:&lt;/p&gt; &lt;pre&gt;apiVersion: config.openshift.io/v1 kind: Build metadata: name: cluster spec: buildDefaults: defaultProxy: httpProxy: http://proxy.com httpsProxy: https://proxy.com noProxy: internal.com env: - name: envkey value: envvalue resources: limits: cpu: 100m memory: 50Mi requests: cpu: 10m memory: 10Mi buildOverrides: nodeSelector: selectorkey: selectorvalue operator: Exists &lt;/pre&gt; &lt;p&gt;Additionally, you should add &lt;code&gt;kube-reserved&lt;/code&gt; and &lt;code&gt;system-reserved&lt;/code&gt; to provide more reliable scheduling and minimize node resource overcommitment in all nodes. Refer to &lt;a href="https://docs.openshift.com/container-platform/4.2/nodes/nodes/nodes-nodes-resources-configuring.html" target="_blank" rel="noopener noreferrer"&gt;Allocating resources for nodes in an OpenShift Container Platform cluster&lt;/a&gt; for more details:&lt;/p&gt; &lt;pre&gt;apiVersion: machineconfiguration.openshift.io/v1 kind: KubeletConfig metadata: name: set-allocatable spec: machineConfigPoolSelector: matchLabels: custom-kubelet: small-pods kubeletConfig: systemReserved: cpu: 500m memory: 512Mi kubeReserved: cpu: 500m memory: 512Mi &lt;/pre&gt; &lt;p&gt;If you have more than 1,000 nodes, you can consider tuning &lt;a href="https://kubernetes.io/docs/concepts/scheduling/scheduler-perf-tuning/" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;percentageOfNodesToScore&lt;/code&gt;&lt;/a&gt; for scheduler performance tuning. This feature&amp;#8217;s state is beta as of Kubernetes 1.14 (OpenShift 4.2).&lt;/p&gt; &lt;h3&gt;Image registry&lt;/h3&gt; &lt;p&gt;This component works on image push and pull tasks for both builds and deployments. First of all, you should consider adopting appropriate storage and network resources to process the required I/O and traffic for the maximum concurrent image pull and push you estimated. Usually, object storage is recommended because it is atomic, meaning the data is either written completely or not written at all, even if there is a failure during the write. Object storage can also share a volume with other duplicated registries in ReadWriteMany (RWX) mode. Further information can be found in the &lt;a href="https://docs.openshift.com/container-platform/4.2/scalability_and_performance/optimizing-storage.html#recommended-configurable-storage-technology_persistent-storage" target="_blank" rel="noopener noreferrer"&gt;Recommended configurable storage technology&lt;/a&gt; documentation.&lt;/p&gt; &lt;p&gt;You can also consider &lt;code&gt;IfNotPresent&lt;/code&gt; &lt;a href="https://docs.openshift.com/container-platform/4.2/openshift_images/managing-images/image-pull-policy.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;ImagePullPolicy&lt;/code&gt;&lt;/a&gt; to reduce the pull/push workload as follows:&lt;/p&gt; &lt;div id="attachment_666627" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-666627" class="wp-image-666627 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/image_policy_table-1024x231.png" alt="The image policy table." width="640" height="144" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/image_policy_table-1024x231.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/image_policy_table-300x68.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/image_policy_table-768x173.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/image_policy_table.png 1408w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-666627" class="wp-caption-text"&gt;Figure 3: The image policy table.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Build pod&lt;/h3&gt; &lt;p&gt;When a build pod is created and starts to build an application, all control passes to the build pod, and the work is configured through build configuration parameters defined by a &lt;code&gt;BuildConfig&lt;/code&gt;. How you choose to create your application and provide source content to build and operate on it all affects build performance.&lt;/p&gt; &lt;p&gt;For instance, if you build a Java or Nodejs application using &lt;code&gt;maven&lt;/code&gt; or &lt;code&gt;npm&lt;/code&gt;, you might download many libraries from their respective external repositories. If at that time the repositories or access path have performance issues, then the build process can fail or be delayed more than usual. This factor means that if your build depends on an external service or resource, it&amp;#8217;s easy to suffer negative effects from that setup regardless of your local system’s status. So, it might be best to consider creating a local repository (&lt;code&gt;maven&lt;/code&gt;, &lt;code&gt;npm&lt;/code&gt;, &lt;code&gt;git&lt;/code&gt;, and so on) to ensure reliable and stable performance for your builds. Or, you can reuse previously downloaded dependencies and previously built artifacts by using &lt;a href="https://docs.openshift.com/container-platform/4.2/builds/build-strategies.html#builds-strategy-s2i-incremental-builds_build-strategies" target="_blank" rel="noopener noreferrer"&gt;Source-to-Image (S2I) incremental builds&lt;/a&gt; if your image registry performance is enough to pull previously-built images for every incremental build:&lt;/p&gt; &lt;pre&gt;strategy: sourceStrategy: from: kind: "ImageStreamTag" name: "incremental-image:latest" incremental: true &lt;/pre&gt; &lt;p&gt;Building with a &lt;code&gt;Dockerfile&lt;/code&gt; can optimize layered caches to decrease image layer pull and push time. In the following example, using this method decreased the update size because splitting into layers is based on change frequency. To rephrase it, any unchanged layers are cached, as shown in Figure 4:&lt;/p&gt; &lt;div id="attachment_666607" style="width: 610px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-666607" class="wp-image-666607" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/layer_cache-300x150.png" alt="An example layer cache." width="600" height="300" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/layer_cache-300x150.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/layer_cache-768x384.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/layer_cache.png 801w" sizes="(max-width: 600px) 100vw, 600px" /&gt;&lt;p id="caption-attachment-666607" class="wp-caption-text"&gt;Figure 4: An example layer cache.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Let&amp;#8217;s look at an example. This image has small layers, but the 35M layer is always updated when the image build is conducted:&lt;/p&gt; &lt;pre&gt;# podman history 31952aa275b8 ID CREATED CREATED BY SIZE COMMENT 31952aa275b8 52 seconds ago /bin/sh -c #(nop) ENTRYPOINT ["tail","-f",... 0B missing 57 seconds ago /bin/sh -c #(nop) COPY resources /resources 35.7MB missing 5 weeks ago 20.48kB missing 5 weeks ago # podman push docker-registry.default.svc:5000/openshift/test:latest Getting image source signatures Copying blob 3698255bccdb done Copying blob a066f3d73913 skipped: already exists Copying blob 26b543be03e2 skipped: already exists Copying config 31952aa275 done Writing manifest to image destination Copying config 31952aa275 done Writing manifest to image destination Storing signatures &lt;/pre&gt; &lt;p&gt;But this image has more layers than the one above, the 5M layer is the only one that is updated. Other unchanged layers are cached:&lt;/p&gt; &lt;pre&gt;# buildah bud --layers . STEP 1: FROM registry.redhat.io/ubi8/ubi-minimal:latest STEP 2: COPY resources/base /resources/base --&amp;#62; Using cache da63ee05ff89cbec02e8a6ac89c287f550337121b8b401752e98c53b22e4fea7 STEP 3: COPY resources/extra /resources/extra --&amp;#62; Using cache 9abc7eee3e705e4999a7f2ffed09d388798d21d1584a5f025153174f1fa161b3 STEP 4: COPY resources/user /resources/user b9cef39450b5e373bd4da14f446b6522e0b46f2aabac2756ae9ce726d240e011 STEP 5: ENTRYPOINT ["tail","-f","/dev/null"] STEP 6: COMMIT 72cc8f59b6cd546d8fb5c3c5d82321b6d14bf66b91367bc5ca403eb33cfcdb15 # podman tag 72cc8f59b6cd docker-registry.default.svc:5000/openshift/test:latest # podman history 72cc8f59b6cd ID CREATED CREATED BY SIZE COMMENT 72cc8f59b6cd About a minute ago /bin/sh -c #(nop) ENTRYPOINT ["tail","-f",... 0B missing About a minute ago /bin/sh -c #(nop) COPY resources/user /res... 5.245MB missing 2 minutes ago /bin/sh -c #(nop) COPY resources/extra /re... 20.07MB missing 2 minutes ago /bin/sh -c #(nop) COPY resources/base /res... 10.49MB missing 5 weeks ago 20.48kB missing 5 weeks ago 107.1MB Imported from - # podman push docker-registry.default.svc:5000/openshift/test:latest Getting image source signatures Copying blob aa6eb6fda701 done Copying blob 26b543be03e2 skipped: already exists Copying blob a066f3d73913 skipped: already exists Copying blob 822ae69b69df skipped: already exists Copying blob 7c5c2aefa536 skipped: already exists Copying config 72cc8f59b6 done Writing manifest to image destination Copying config 72cc8f59b6 done Writing manifest to image destination Storing signatures &lt;/pre&gt; &lt;p&gt;You should check your build logs when troubleshooting the build process because Kubernetes can only detect whether a build pod completed successfully or not.&lt;/p&gt; &lt;h3&gt;Application pod&lt;/h3&gt; &lt;p&gt;Like the build pod, all control passes to the application pod once the application pod is created, so most of the work is done through the application implementation if the application depends on external services and resources to initialize, such as DB connection pooling, KVS, and other API connections. And you should also watch out whether &lt;code&gt;Security Software&lt;/code&gt; is running on your hosts. It can usually affect all processes on the hosts, not only deployment.&lt;/p&gt; &lt;p&gt;For instance, if DB server that uses connection pooling has performance issues or reaches the maximum connection count while the application pod is starting, the application pod initialization can be delayed more than expected. So, if your application has external dependencies, you should also check to see whether they are running well. And if &lt;code&gt;Readiness Probes&lt;/code&gt; and &lt;code&gt;Liveness Probes&lt;/code&gt; are configured for your application pod, you should set &lt;code&gt;initialDelaySeconds&lt;/code&gt; and &lt;code&gt;periodSeconds&lt;/code&gt; large enough for your application pod to initialize. If your &lt;code&gt;initialDelaySeconds&lt;/code&gt; and &lt;code&gt;periodSeconds&lt;/code&gt; are too short to check the application states, your application will be restarted repeatedly and might result in a delay or failure to deploy the application pod (you can find more on this issue in &lt;a href="https://docs.openshift.com/container-platform/4.2/nodes/containers/nodes-containers-health.html" target="_blank" rel="noopener noreferrer"&gt;Monitoring container health&lt;/a&gt;):&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: Pod metadata: labels: test: liveness name: liveness-http spec: containers: - name: liveness-http image: k8s.gcr.io/liveness args: - /server livenessProbe: httpGet: # host: my-host # scheme: HTTPS path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 15 timeoutSeconds: 1 name: liveness &lt;/pre&gt; &lt;h2&gt;Build and deployment in parallel&lt;/h2&gt; &lt;p&gt;Lastly, I recommend that you keep concurrent build and deployment tasks in one cycle as appropriate numbers for suppressing resource issues. As you can see here, these tasks are chained with other tasks and they will iterate automatically through their life cycles, so there would be more workload than you expected. Usually, the compile (build) and application initialization (deployment) processes are CPU-intensive tasks, so you might need to evaluate how many concurrent build and deployment tasks are possible to ensure you have a stable cluster before scheduling new tasks.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;We took a look at how each part affects each other within build and deployment processes. I focused on the configuration and other information related only to build and deployment performance topics in the hopes that this information will help your understanding regarding the interaction between the build and deployment phases of applications on OpenShift. I hope this information is helpful for your stable system management. Thank you for reading.&lt;/p&gt; &lt;h2&gt;References&lt;/h2&gt; &lt;p&gt;Two additional references you might find useful are &lt;a href="https://docs.openshift.com/container-platform/4.2/builds/understanding-image-builds.html" target="_blank" rel="noopener noreferrer"&gt;OpenShift Container Platform 4.2 Documentation &amp;#8211; Understanding image builds&lt;/a&gt; and &lt;a href="https://kubernetes.io/docs/concepts/scheduling/scheduler-perf-tuning/" target="_blank" rel="noopener noreferrer"&gt;Scheduler Performance Tuning&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fhow-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20maintain%20stable%20build%20and%20deployment%20performance%20on%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fhow-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20maintain%20stable%20build%20and%20deployment%20performance%20on%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fhow-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20maintain%20stable%20build%20and%20deployment%20performance%20on%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fhow-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20maintain%20stable%20build%20and%20deployment%20performance%20on%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fhow-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20maintain%20stable%20build%20and%20deployment%20performance%20on%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fhow-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20maintain%20stable%20build%20and%20deployment%20performance%20on%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fhow-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift%2F&amp;#38;linkname=How%20to%20maintain%20stable%20build%20and%20deployment%20performance%20on%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fhow-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift%2F&amp;#038;title=How%20to%20maintain%20stable%20build%20and%20deployment%20performance%20on%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2020/01/23/how-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift/" data-a2a-title="How to maintain stable build and deployment performance on Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/23/how-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift/"&gt;How to maintain stable build and deployment performance on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-_hIb6PgPQU" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In this article, I will introduce helpful, common tips for managing reliable builds and deployments on Red Hat OpenShift. If you have experienced a sudden performance degradation for builds and deployments on OpenShift, it might be helpful to troubleshoot your cluster. We will start by reviewing the whole process, from build to deployment, and then [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/23/how-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift/"&gt;How to maintain stable build and deployment performance on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">666597</post-id><dc:creator>Daein Park</dc:creator><dc:date>2020-01-23T08:00:14Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/23/how-to-maintain-stable-build-and-deployment-performance-on-red-hat-openshift/</feedburner:origLink></entry><entry><title>Using Kubernetes ConfigMaps to define your Quarkus application’s properties</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/yXPhM1YYEQc/" /><category term="DevOps" /><category term="Kubernetes" /><category term="Quarkus" /><category term="Cluster" /><category term="configmap" /><category term="deploy app" /><category term="Docker" /><category term="Java" /><author><name>Sébastien Blanc</name></author><id>https://developers.redhat.com/blog/?p=675247</id><updated>2020-01-23T08:00:10Z</updated><published>2020-01-23T08:00:10Z</published><content type="html">&lt;p&gt;So, you wrote your Quarkus application, and now you want to deploy it to a Kubernetes cluster. Good news: Deploying a Quarkus application to a Kubernetes cluster is easy. Before you do this, though, you need to straighten out your application&amp;#8217;s properties. After all, your app probably has to connect with a database, call other services, and so on. These settings are already defined in your &lt;code&gt;application.properties&lt;/code&gt; file, but the values match the ones for your local environment and won&amp;#8217;t work once deployed onto your cluster.&lt;/p&gt; &lt;p&gt;So, how do you easily solve this problem? Let&amp;#8217;s walk through an example.&lt;/p&gt; &lt;p&gt;&lt;span id="more-675247"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Create the example Quarkus application&lt;/h2&gt; &lt;p&gt;Instead of using a complex example, let&amp;#8217;s take a simple use case that explains the concept well. Start by creating a new Quarkus app:&lt;/p&gt; &lt;pre&gt;$ mvn io.quarkus:quarkus-maven-plugin:1.1.1.Final:create&lt;/pre&gt; &lt;p&gt;You can keep all of the default values while creating the new application. In this example, the application is named &lt;code&gt;hello-app&lt;/code&gt;. Now, open the &lt;code&gt;HelloResource.java&lt;/code&gt; file and refactor it to look like this:&lt;/p&gt; &lt;pre&gt;@Path("/hello") public class HelloResource { @ConfigProperty(name = "greeting.message") String message; @GET @Produces(MediaType.TEXT_PLAIN) public String hello() { return "hello " + message; } } &lt;/pre&gt; &lt;p&gt;In your &lt;code&gt;application.properties&lt;/code&gt; file, now add &lt;code&gt;greeting.message=localhost&lt;/code&gt;. The &lt;code&gt;@ConfigProperty&lt;/code&gt; annotation is not in the scope of this article, but here we can see how easy it is to inject properties inside our code using this annotation.&lt;/p&gt; &lt;p&gt;Now, let&amp;#8217;s start our application to see if it works as expected: &lt;code&gt;&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;$ mvn compile quarkus:dev&lt;/pre&gt; &lt;p&gt;Browse to &lt;code&gt;http://localhost:8080/hello&lt;/code&gt;, which should output &lt;code&gt;hello localhost&lt;/code&gt;. That&amp;#8217;s it for the Quarkus app. It&amp;#8217;s ready to go.&lt;/p&gt; &lt;h2&gt;Deploy the application to the Kubernetes cluster&lt;/h2&gt; &lt;p&gt;The idea here is to deploy this application to our Kubernetes cluster and replace the value of our &lt;code&gt;greeting&lt;/code&gt; property with one that will work on the cluster. It is important to know here that all of the properties from &lt;code&gt;application.properties&lt;/code&gt; are exposed, and thus can be overridden with environment variables. The convention is to convert the name of the property to uppercase and replace every dot (&lt;code&gt;.&lt;/code&gt;) with an underscore (&lt;code&gt;_&lt;/code&gt;). So, for instance, our &lt;code&gt;greeting.message&lt;/code&gt; will become &lt;code&gt;GREETING_MESSAGE&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;At this point, we are almost ready to deploy our app to Kubernetes, but we need to do three more things:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a Docker image of your application and push it to a repository that your cluster can access.&lt;/li&gt; &lt;li&gt;Define a ConfgMap resource.&lt;/li&gt; &lt;li&gt;Generate the Kubernetes resources for our application.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;To create the Docker image, simply execute this command:&lt;/p&gt; &lt;pre&gt;$ docker build -f src/main/docker/Dockerfile.jvm -t quarkus/hello-app .&lt;/pre&gt; &lt;p&gt;Be sure to set the right Docker username and to also push to an image registry, like &lt;code&gt;docker-hub&lt;/code&gt; or &lt;code&gt;quay&lt;/code&gt;. If you are not able to push an image, you can use &lt;code&gt;sebi2706/hello-app:latest&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Next, create the file &lt;code&gt;config-hello.yml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 data: greeting: "Kubernetes" kind: ConfigMap metadata: name: hello-config &lt;/pre&gt; &lt;p&gt;Make sure that you are connected to a cluster and apply this file:&lt;/p&gt; &lt;pre&gt;$ kubectl apply -f config-hello.yml&lt;/pre&gt; &lt;p&gt;Quarkus comes with a useful extension, &lt;code&gt;quarkus-kubernetes&lt;/code&gt;, that generates the Kubernetes resources for you. You can even tweak the generated resources by providing extra properties—for more details, check out this &lt;a href="https://quarkus.io/guides/kubernetes" target="_blank" rel="noopener noreferrer"&gt;guide&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;After installing the extension, add these properties to our &lt;code&gt;application.properties&lt;/code&gt; file so it generates extra configuration arguments for our containers specification:&lt;/p&gt; &lt;pre&gt;kubernetes.group=yourDockerUsername kubernetes.env-vars[0].name=GREETING_MESSAGE kubernetes.env-vars[0].value=greeting kubernetes.env-vars[0].configmap=hello-config&lt;/pre&gt; &lt;p&gt;Run &lt;code&gt;mvn package&lt;/code&gt; and view the generated resources in &lt;code&gt;target/kubernetes&lt;/code&gt;. The interesting part is in &lt;code&gt;spec.containers.env&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;- name: "GREETING_MESSAGE"   valueFrom:   configMapKeyRef:     key: "greeting"    name: "hello-config"&lt;/pre&gt; &lt;p&gt;Here, we see how to pass an environment variable to our container with a value coming from a ConfigMap. Now, simply apply the resources:&lt;/p&gt; &lt;pre&gt;$ kubectl apply -f target/kubernetes/kubernetes.yml&lt;/pre&gt; &lt;p&gt;Expose your service:&lt;/p&gt; &lt;pre class="highlightjs highlight"&gt;&lt;code class="language-shell hljs" data-lang="shell"&gt;kubectl expose deployment hello --type=NodePort&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, browse to the public URL or do a curl. For instance, with Minikube:&lt;/p&gt; &lt;pre class="highlightjs highlight"&gt;&lt;code class="language-shell hljs" data-lang="shell"&gt;$ curl $(minikube service hello-app --url)/hello&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This command should output: &lt;code&gt;hello Kubernetes&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Now you know how to use a ConfigMap in combination with environment variables and your Quarkus&amp;#8217;s &lt;code&gt;application.properties&lt;/code&gt;. As we said in the introduction, this technique is particularly useful when defining a DB connection&amp;#8217;s URL (like &lt;code&gt;QUARKUS_DATASOURCE_URL&lt;/code&gt;) or when using the &lt;code&gt;quarkus-rest-client&lt;/code&gt; (&lt;code&gt;ORG_SEBI_OTHERSERVICE_MP_REST_URL&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fusing-kubernetes-configmaps-to-define-your-quarkus-applications-properties%2F&amp;#38;linkname=Using%20Kubernetes%20ConfigMaps%20to%20define%20your%20Quarkus%20application%E2%80%99s%20properties" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fusing-kubernetes-configmaps-to-define-your-quarkus-applications-properties%2F&amp;#38;linkname=Using%20Kubernetes%20ConfigMaps%20to%20define%20your%20Quarkus%20application%E2%80%99s%20properties" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fusing-kubernetes-configmaps-to-define-your-quarkus-applications-properties%2F&amp;#38;linkname=Using%20Kubernetes%20ConfigMaps%20to%20define%20your%20Quarkus%20application%E2%80%99s%20properties" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fusing-kubernetes-configmaps-to-define-your-quarkus-applications-properties%2F&amp;#38;linkname=Using%20Kubernetes%20ConfigMaps%20to%20define%20your%20Quarkus%20application%E2%80%99s%20properties" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fusing-kubernetes-configmaps-to-define-your-quarkus-applications-properties%2F&amp;#38;linkname=Using%20Kubernetes%20ConfigMaps%20to%20define%20your%20Quarkus%20application%E2%80%99s%20properties" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fusing-kubernetes-configmaps-to-define-your-quarkus-applications-properties%2F&amp;#38;linkname=Using%20Kubernetes%20ConfigMaps%20to%20define%20your%20Quarkus%20application%E2%80%99s%20properties" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fusing-kubernetes-configmaps-to-define-your-quarkus-applications-properties%2F&amp;#38;linkname=Using%20Kubernetes%20ConfigMaps%20to%20define%20your%20Quarkus%20application%E2%80%99s%20properties" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F23%2Fusing-kubernetes-configmaps-to-define-your-quarkus-applications-properties%2F&amp;#038;title=Using%20Kubernetes%20ConfigMaps%20to%20define%20your%20Quarkus%20application%E2%80%99s%20properties" data-a2a-url="https://developers.redhat.com/blog/2020/01/23/using-kubernetes-configmaps-to-define-your-quarkus-applications-properties/" data-a2a-title="Using Kubernetes ConfigMaps to define your Quarkus application’s properties"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/23/using-kubernetes-configmaps-to-define-your-quarkus-applications-properties/"&gt;Using Kubernetes ConfigMaps to define your Quarkus application&amp;#8217;s properties&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/yXPhM1YYEQc" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;So, you wrote your Quarkus application, and now you want to deploy it to a Kubernetes cluster. Good news: Deploying a Quarkus application to a Kubernetes cluster is easy. Before you do this, though, you need to straighten out your application&amp;#8217;s properties. After all, your app probably has to connect with a database, call other [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/23/using-kubernetes-configmaps-to-define-your-quarkus-applications-properties/"&gt;Using Kubernetes ConfigMaps to define your Quarkus application&amp;#8217;s properties&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">675247</post-id><dc:creator>Sébastien Blanc</dc:creator><dc:date>2020-01-23T08:00:10Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/23/using-kubernetes-configmaps-to-define-your-quarkus-applications-properties/</feedburner:origLink></entry><entry><title>Operator pattern: REST API for Kubernetes and Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/VkYby_fGSUw/" /><category term="Containers" /><category term="Kubernetes" /><category term="Operator" /><category term="CodeReady Containers" /><category term="openshift" /><category term="operator patterns" /><category term="REST API" /><author><name>akoserwa</name></author><id>https://developers.redhat.com/blog/?p=664347</id><updated>2020-01-22T08:00:53Z</updated><published>2020-01-22T08:00:53Z</published><content type="html">&lt;p&gt;In this article, we will see a similar pattern when writing the REST API in any known framework vs. writing an Operator using Kubernetes&amp;#8217; client libraries. The idea behind this article is not to explain how to write a REST API, but instead to explain the internals of &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; by working with an analogy.&lt;/p&gt; &lt;h2&gt;Local setup&lt;/h2&gt; &lt;p&gt;To follow along, you will need the following installed:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Go version 13.4&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/operator-framework/operator-sdk" target="_blank" rel="noopener noreferrer"&gt;operator-sdk&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/code-ready/crc" target="_blank" rel="noopener nofollow noreferrer"&gt;CodeReady Containers &lt;/a&gt;(OpenShift version 4.2)&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.2/welcome/index.html" target="_blank" rel="noopener noreferrer"&gt;oc&lt;/a&gt; and &lt;a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank" rel="noopener noreferrer"&gt;kubectl&lt;/a&gt;&lt;/li&gt; &lt;li&gt;This &lt;a href="https://github.com/akoserwal/customer-api" target="_blank" rel="noopener noreferrer"&gt;code repo&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;As a developer, if you have used the REST API with frameworks like Quarkus/Spring (Java), Express (Nodejs), Ruby on Rails, Flask (Python), Golang (mux), etc., understanding and writing an operator will be easier for you. We will use this experience with other languages or frameworks to build our understanding.&lt;span id="more-664347"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;By writing an operator, you implement a REST API using Kubernetes client libraries as your framework—i.e., extending the Kubernetes APIs with your custom logic. If you are running a single-cluster Kubernetes instance locally using CRC/Minishift/Minikube, etc., type this command into the terminal:&lt;/p&gt; &lt;pre&gt;$ kubectl proxy&lt;/pre&gt; &lt;p&gt;The Kubernetes API endpoints are as shown in Figure 1:&lt;/p&gt; &lt;div id="attachment_667937" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-667937" class=" size-large wp-image-667937 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern1-1024x640.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern1-1024x640.png" alt="Kubernetes API endpoints." width="640" height="400" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern1-1024x640.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern1-300x188.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern1-768x480.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-667937" class="wp-caption-text"&gt;Figure 1: Kubernetes API endpoints.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As you can see, each entity within the Kubernetes domain space is an exposed API endpoint. Whenever you trigger a deployment or scale up a pod, you hit these APIs behind the scenes.&lt;/p&gt; &lt;p&gt;We can start by writing a REST API in the framework that is familiar. I will use &lt;a href="https://spring.io/projects/spring-boot" target="_blank" rel="noopener noreferrer"&gt;Spring Boot&lt;/a&gt; for building a simple Customer API. Later, we will write a &lt;code&gt;customer-api-operator&lt;/code&gt; that extends Kubernetes&amp;#8217; &lt;code&gt;api-server&lt;/code&gt; with our defined Customer API. If you are not familiar with Spring Boot, you can continue. The main idea is just to understand the analogy that writing the API using any language and using the Kubernetes client libraries follows nearly the same pattern.&lt;/p&gt; &lt;h2&gt;Example: REST API&lt;/h2&gt; &lt;p&gt;Let’s start the REST API side of this analogy by defining our &lt;code&gt;Customer&lt;/code&gt; model class, as shown in Figure 2:&lt;/p&gt; &lt;div id="attachment_667967" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-667967" class=" size-large wp-image-667967 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern2-1024x361.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern2-1024x361.png" alt="Customer model class definition." width="640" height="226" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern2-1024x361.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern2-300x106.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern2-768x271.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-667967" class="wp-caption-text"&gt;Figure 2: Customer model class definition.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, we need the controller, which exposes a &lt;code&gt;Customer&lt;/code&gt; REST endpoint and handles the request/response process. Let&amp;#8217;s define three endpoints (&lt;code&gt;current&lt;/code&gt;, &lt;code&gt;desired&lt;/code&gt;, and &lt;code&gt;reconcile&lt;/code&gt;) and a &lt;code&gt;CustomerReconciler&lt;/code&gt; service that handles the business logic, as shown in Figure 3:&lt;/p&gt; &lt;div id="attachment_667997" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-667997" class=" size-large wp-image-667997 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern3-1024x688.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern3-1024x688.png" alt="CustomerReconciler service definition." width="640" height="430" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern3-1024x688.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern3-300x201.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern3-768x516.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-667997" class="wp-caption-text"&gt;Figure 3: CustomerReconciler service definition.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Start your Spring Boot application with:&lt;/p&gt; &lt;pre&gt;$ mvn spring-boot:run&lt;/pre&gt; &lt;p&gt;This command starts the application on the default port. Let’s hit our API to get the current state of our customers using values I mocked for this demo. In general, we fetch this information from other APIs or databases, but for this example Figure 4 shows the current state of our Kubernetes pods:&lt;/p&gt; &lt;div id="attachment_668007" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668007" class=" size-large wp-image-668007 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern4-1024x457.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern4-1024x457.png" alt="" width="640" height="286" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern4-1024x457.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern4-300x134.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern4-768x343.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern4.png 1079w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668007" class="wp-caption-text"&gt;Figure 4: The artificially-created current pod state.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, let’s try to update the state of our &lt;code&gt;Customer&lt;/code&gt; with a desired state using the POST method and JSON data as shown in Figure 5:&lt;/p&gt; &lt;div id="attachment_668037" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668037" class=" size-large wp-image-668037 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern5-1024x290.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern5-1024x290.png" alt="The JSON data." width="640" height="181" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern5-1024x290.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern5-300x85.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern5-768x217.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern5.png 1434w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668037" class="wp-caption-text"&gt;Figure 5: The JSON state data.&lt;/p&gt;&lt;/div&gt; &lt;p data-selectable-paragraph=""&gt;In Kubernetes, updating the state from &lt;em&gt;current&lt;/em&gt; to &lt;em&gt;desired&lt;/em&gt; is handled by the &lt;code&gt;reconcile&lt;/code&gt; endpoint, which shows the difference between the current state and the desired state. We defined our business logic to handle this state in the reconciler loop shown in Figure 6:&lt;/p&gt; &lt;div id="attachment_668047" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668047" class=" size-large wp-image-668047 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern6-1024x570.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern6-1024x570.png" alt="The reconciler state data." width="640" height="356" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern6-1024x570.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern6-300x167.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern6-768x427.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern6.png 1148w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668047" class="wp-caption-text"&gt;Figure 6: The reconciler state data.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now we have a Customer API that can get the customer&amp;#8217;s current state, update the state, and reconcile it to handle the change.&lt;/p&gt; &lt;h2&gt;Example: Custom operator&lt;/h2&gt; &lt;p&gt;Now let&amp;#8217;s see how to implement a similar API by extending the Kubernetes API server using the &lt;a href="https://github.com/operator-framework/operator-sdk" target="_blank" rel="noopener noreferrer"&gt;Operator SDK&lt;/a&gt;. First, generate the Operator:&lt;/p&gt; &lt;pre&gt;$ operator-sdk new &lt;strong&gt;&lt;em&gt;customer-api-operator&lt;/em&gt;&lt;/strong&gt;&lt;/pre&gt; &lt;p&gt;This action generates basic boilerplate code for our Customer API Operator, as shown in Figure 7:&lt;/p&gt; &lt;div id="attachment_668097" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668097" class=" size-large wp-image-668097 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern7-1024x311.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern7-1024x311.png" alt="Basic boilerplate code for our new API Operator." width="640" height="194" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern7-1024x311.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern7-300x91.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern7-768x233.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668097" class="wp-caption-text"&gt;Figure 7: Basic boilerplate code for our new API Operator.&lt;/p&gt;&lt;/div&gt; &lt;p id="981c" class="ir is cm ar it b iu iv iw ix iy iz ja jb jc jd je" data-selectable-paragraph=""&gt;Start by adding the model data type (i.e., &lt;code&gt;Customer&lt;/code&gt;), where &lt;em&gt;kind&lt;/em&gt; is an entity like a pod&lt;strong&gt;, &lt;/strong&gt;node, deployment&lt;strong&gt;,&lt;/strong&gt; etc. Next, add a custom API for the Kubernetes platform, which requires generating a new &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/" target="_blank" rel="noopener noreferrer"&gt;Custom Resource Definition&lt;/a&gt; (CRD) with an API version:&lt;/p&gt; &lt;pre&gt;$ operator-sdk add &lt;strong&gt;api&lt;/strong&gt; --api-version=akoserwal.io/v1alpha1 --kind=&lt;strong&gt;Customer&lt;/strong&gt;&lt;/pre&gt; &lt;p&gt;This command generates a basic scaffolding for our Customer API. Half of the work for defining a basic model is now already done by the SDK. You can look into the file &lt;a href="https://github.com/akoserwal/customer-api/blob/master/customer-api-operator/pkg/apis/customer/v1alpha1/customer_types.go" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;customer_types.go&lt;/code&gt;&lt;/a&gt; (the same as your model class, &lt;a href="https://github.com/akoserwal/customer-api/blob/master/CustomerAPI/src/main/java/io/akoserwal/CustomerAPI/model/Customer.java" target="_blank" rel="noopener noreferrer"&gt;customer.java&lt;/a&gt;, defined in the first example)&lt;em&gt;.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;In Figure 8, you can see that &lt;code&gt;Spec&lt;/code&gt; and &lt;code&gt;Status&lt;/code&gt; are already pre-defined with the generated &lt;code&gt;Customer&lt;/code&gt; struct and that we add the new entities from the Customer model class (i.e., &lt;code&gt;FirstName&lt;/code&gt;, &lt;code&gt;LastName&lt;/code&gt;, and &lt;code&gt;Email&lt;/code&gt;):&lt;/p&gt; &lt;div id="attachment_668177" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668177" class=" size-large wp-image-668177 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern8-1024x553.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern8-1024x553.png" alt="The pre-defined Customer struct." width="640" height="346" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern8-1024x553.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern8-300x162.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern8-768x415.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668177" class="wp-caption-text"&gt;Figure 8: The pre-defined Customer struct.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After modifying &lt;code&gt;customer_types.go&lt;/code&gt;, run these commands for deep copy and generating an OpenAPI spec for the Customer API:&lt;/p&gt; &lt;pre&gt;$ operator-sdk generate k8s $ operator-sdk generate openapi&lt;/pre&gt; &lt;p&gt;Now, generate the controller:&lt;/p&gt; &lt;pre&gt;$ operator-sdk add &lt;strong&gt;controller&lt;/strong&gt; --api-version=akoserwal.io/v1alpha1 --kind=Customer &lt;/pre&gt; &lt;p&gt;The generated boilerplate controller code adds our Customer API schema to the Kubernetes schema. Next, we add a couple of watchers to look out for any changes or events, which triggers the reconciler loop for handling the changes as you can see in Figure 9:&lt;/p&gt; &lt;div id="attachment_668247" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668247" class=" size-large wp-image-668247 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern9-1024x647.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern9-1024x647.png" alt="The controller boilerplate code." width="640" height="404" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern9-1024x647.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern9-300x189.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern9-768x485.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668247" class="wp-caption-text"&gt;Figure 9: The controller boilerplate code.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can relate this result to the Spring Boot example&amp;#8217;s &lt;code&gt;CustomerController&lt;/code&gt; and reconciler endpoint. Although, this version does more than our Spring Boot controller.&lt;/p&gt; &lt;p&gt;You can see the simplified flow in Figure 10:&lt;/p&gt; &lt;div id="attachment_668287" style="width: 815px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668287" class=" size-large wp-image-668287 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern10.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern10.png" alt="The simplified API flow." width="805" height="448" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern10.png 805w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern10-300x167.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern10-768x427.png 768w" sizes="(max-width: 805px) 100vw, 805px" /&gt;&lt;p id="caption-attachment-668287" class="wp-caption-text"&gt;Figure 10: The simplified API flow.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;So, to reiterate, creating a custom Operator—instead of using a REST API in your chosen framework—flows as follows:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Define a namespace for our operator (i.e.,&lt;code&gt;Customer&lt;/code&gt;).&lt;/li&gt; &lt;li&gt;Create the Customer Resource Definition (CRD), so define the &amp;#8220;kind&amp;#8221; (i.e., the customer as a resource in OpenShift/Kubernetes).&lt;/li&gt; &lt;li&gt;Let the controller analyze the CRD and add that information to the Kubernetes API schema.&lt;/li&gt; &lt;li&gt;Expose a new API endpoint for the CRD.&lt;/li&gt; &lt;li&gt;Add watchers for the namespace to observe.&lt;/li&gt; &lt;li&gt;Run a process/loop (i.e., reconciler loop) for acting based on the desired change.&lt;/li&gt; &lt;li&gt;Store the state in the EtcD.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Now that the custom Operator is defined, let&amp;#8217;s continue. Deploy the Operator:&lt;/p&gt; &lt;pre&gt;$ crc start&lt;/pre&gt; &lt;p&gt;Log into the CRC instance:&lt;/p&gt; &lt;pre&gt;$ oc login -u kubeadmin -p &amp;#60;secret&amp;#62;&lt;/pre&gt; &lt;p&gt;Create the custom CRD:&lt;/p&gt; &lt;pre&gt;$ oc create -f deploy/crds/customer.github.io_customers_crd.yaml&lt;/pre&gt; &lt;p&gt;Add the roles, &lt;code&gt;role_binding&lt;/code&gt;, and service account for the customer. These settings define the permissions and rules regarding access to our Operator:&lt;/p&gt; &lt;pre&gt;$ kubectl create -f deploy/role.yaml $ kubectl create -f deploy/role_binding.yaml $ kubectl create -f deploy/service_account.yaml &lt;/pre&gt; &lt;p&gt;Run our Operator locally:&lt;/p&gt; &lt;pre&gt;$ export NAMESPACE=customer $ operator-sdk up local&lt;/pre&gt; &lt;p&gt;Now our controller is in the running state. It watches the &lt;code&gt;NAMESPACE&lt;/code&gt; for any changes.&lt;/p&gt; &lt;p&gt;Create an instance of the CRD by creating a Custom Resource object:&lt;/p&gt; &lt;pre&gt;$ oc create -f deploy/crds/customer.github.io_v1alpha1_customer_cr.yaml&lt;/pre&gt; &lt;p&gt;Once created, the CR looks like this:&lt;/p&gt; &lt;pre&gt;apiVersion: customer.github.io/v1alpha1 kind: Customer metadata: name: customer-api spec: &lt;em class="mj"&gt;# Add fields here &lt;/em&gt;size: 3 firstName: Abhishek lastName: Koserwal email: ak..@redhat.com&lt;/pre&gt; &lt;p&gt;When we create a CR object, an event is triggered that gives control to the reconciler loop. Reconcile reads the state of that cluster for a custom object and makes changes based on the state it reads.&lt;/p&gt; &lt;p&gt;Figure 11 shows the Customer Custom Resource in the OpenShift UI:&lt;/p&gt; &lt;div id="attachment_668377" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668377" class=" size-large wp-image-668377 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern11-1024x761.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern11-1024x761.png" alt="The new Custom Resource in the OpenShift API." width="640" height="476" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern11-1024x761.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern11-300x223.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern11-768x571.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern11.png 1548w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668377" class="wp-caption-text"&gt;Figure 11: The new Custom Resource in the OpenShift API.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 12 shows the Customer Custom Resource in its raw API format:&lt;/p&gt; &lt;div id="attachment_668387" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668387" class=" size-large wp-image-668387 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern12-1024x501.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern12-1024x501.png" alt="The new Custom Resource as a raw API." width="640" height="313" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern12-1024x501.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern12-300x147.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern12-768x376.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668387" class="wp-caption-text"&gt;Figure 12: The new Custom Resource as a raw API.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Based on the logic inside our reconciler loop, this CR object creates a pod for the instance &lt;code&gt;customer-api&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;// Define a new Pod object pod := newPodForCR(instance)&lt;/pre&gt; &lt;p&gt;Figure 13 shows such an instance:&lt;/p&gt; &lt;div id="attachment_668447" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668447" class=" size-large wp-image-668447 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14-1024x601.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14-1024x601.png" alt="Additional update logic." width="640" height="376" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14-1024x601.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14-300x176.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14-768x451.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14.png 1121w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668447" class="wp-caption-text"&gt;Figure 13: Additional update logic.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, we can add update logic for defining the desired state for our existing Custom Resource. Let’s update the reconciler so it will update our CR (&lt;code&gt;firstName&lt;/code&gt;, &lt;code&gt;lastName&lt;/code&gt;, and &lt;code&gt;Email&lt;/code&gt;) as shown in Figure 14:&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/akoserwal/customer-api/blob/master/customer-api-operator/pkg/controller/customer/customer_controller.go"&gt;customer_controller.go&lt;/a&gt; [func (r *ReconcileCustomer) Reconcile]&lt;/p&gt; &lt;div id="attachment_668447" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668447" class=" size-large wp-image-668447 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14-1024x601.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14-1024x601.png" alt="Additional update logic." width="640" height="376" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14-1024x601.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14-300x176.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14-768x451.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern14.png 1121w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668447" class="wp-caption-text"&gt;Figure 14: Additional update logic.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, re-run the Operator:&lt;/p&gt; &lt;pre&gt;$ operator-sdk up local&lt;/pre&gt; &lt;p&gt;Finally, in Figure 15, we can see that the reconciler has updated the desired state for the Custom Resource:&lt;/p&gt; &lt;div id="attachment_668477" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-668477" class=" size-large wp-image-668477 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern15-1024x635.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern15-1024x635.png" alt="The updated desired state." width="640" height="397" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern15-1024x635.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern15-300x186.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern15-768x476.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/operatorpattern15.png 1575w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-668477" class="wp-caption-text"&gt;Figure 15: The updated desired state.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;Operator patterns allow you to use Kubernetes platform capabilities to run custom business logic. These patterns are powerful, and they are capable of doing way more than what I have covered here. In this article, I focused on Kubernetes internals and Operator patterns with a relatable approach via the REST API. Writing these types of extensions is not the best use case for Operator patterns. You can run a Spring Boot—or any other language—application in a container for use cases such as &amp;#8220;building a REST API application/service.&amp;#8221; For actual use cases, visit &lt;a href="https://operatorhub.io" target="_blank" rel="noopener noreferrer"&gt;operatorhub.io&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Thank you for reading, I hope you find this article helpful. You can &lt;a href="https://github.com/akoserwal/customer-api" target="_blank" rel="noopener noreferrer"&gt;find the code here&lt;/a&gt;. Happy coding.&lt;/p&gt; &lt;h3&gt;References&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/operator-framework/operator-sdk" target="_blank" rel="noopener noreferrer"&gt;operator-sdk &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/operator-framework/awesome-operators" target="_blank" rel="noopener noreferrer"&gt;awesome-operators&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/operator-framework" target="_blank" rel="noopener noreferrer"&gt;operator-framework&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/operator-framework/getting-started" target="_blank" rel="noopener noreferrer"&gt;getting-started&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://coreos.com/operators" target="_blank" rel="noopener noreferrer"&gt;Operator&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://operatorhub.io" target="_blank" rel="noopener noreferrer"&gt;OperatorHub&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Foperator-pattern-rest-api-for-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Operator%20pattern%3A%20REST%20API%20for%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Foperator-pattern-rest-api-for-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Operator%20pattern%3A%20REST%20API%20for%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Foperator-pattern-rest-api-for-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Operator%20pattern%3A%20REST%20API%20for%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Foperator-pattern-rest-api-for-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Operator%20pattern%3A%20REST%20API%20for%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Foperator-pattern-rest-api-for-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Operator%20pattern%3A%20REST%20API%20for%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Foperator-pattern-rest-api-for-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Operator%20pattern%3A%20REST%20API%20for%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Foperator-pattern-rest-api-for-kubernetes-and-red-hat-openshift%2F&amp;#38;linkname=Operator%20pattern%3A%20REST%20API%20for%20Kubernetes%20and%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Foperator-pattern-rest-api-for-kubernetes-and-red-hat-openshift%2F&amp;#038;title=Operator%20pattern%3A%20REST%20API%20for%20Kubernetes%20and%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2020/01/22/operator-pattern-rest-api-for-kubernetes-and-red-hat-openshift/" data-a2a-title="Operator pattern: REST API for Kubernetes and Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/22/operator-pattern-rest-api-for-kubernetes-and-red-hat-openshift/"&gt;Operator pattern: REST API for Kubernetes and Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/VkYby_fGSUw" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In this article, we will see a similar pattern when writing the REST API in any known framework vs. writing an Operator using Kubernetes&amp;#8217; client libraries. The idea behind this article is not to explain how to write a REST API, but instead to explain the internals of Kubernetes by working with an analogy. Local [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/22/operator-pattern-rest-api-for-kubernetes-and-red-hat-openshift/"&gt;Operator pattern: REST API for Kubernetes and Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">664347</post-id><dc:creator>akoserwa</dc:creator><dc:date>2020-01-22T08:00:53Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/22/operator-pattern-rest-api-for-kubernetes-and-red-hat-openshift/</feedburner:origLink></entry><entry><title>Why not couple an Operator’s logic to a specific Kubernetes platform?</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Ie5nCx_LiUA/" /><category term="DevOps" /><category term="Kubernetes" /><category term="Operator" /><category term="Golang" /><category term="OLM" /><category term="openshift" /><author><name>Camila Macedo</name></author><id>https://developers.redhat.com/blog/?p=666287</id><updated>2020-01-22T08:00:09Z</updated><published>2020-01-22T08:00:09Z</published><content type="html">&lt;p&gt;You might find yourself in situations where you believe that a logic implementation should occur only if and when your Operator is running on a specific Kubernetes platform. So, you probably want to know how to get the cluster vendor from the operator. In this article, we will discuss why relying on the vendor is not a good idea. Also, we will show how to solve this kind of scenario.&lt;/p&gt; &lt;p&gt;&lt;span id="more-666287"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;Why not develop solutions based on the vendor?&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s think about the scenario where we have an Operator that will take further actions only if the Operator Lifecycle Manager (&lt;a href="https://github.com/operator-framework/operator-lifecycle-manager" target="_blank" rel="noopener noreferrer"&gt;OLM&lt;/a&gt;) is installed in the cluster. Then, could we not check whether the cluster is an OpenShift platform because the OLM is provided by default?&lt;/p&gt; &lt;p&gt;No, we cannot. Note that besides the OLM being installed and available in OpenShift 4.X via the default installation, it also might not always be truthful. And then, it is essential to highlight that the OLM can be installed on other vendors as well.&lt;/p&gt; &lt;p&gt;Thus, this example provides a pretty good idea of the problems that can be caused by relying on such assumptions.&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;What&amp;#8217;s the best approach, then?&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;The best approach to handle this scenario is to look for the exact API resource that is required for the solution, instead of using a resource that assumes the Operator is running or not on a specific Kubernetes platform.&lt;/p&gt; &lt;p&gt;In the above case, we were looking to see if the OLM&amp;#8217;s Custom Resources Definitions (API Resource), which are essential to the solution, are present or not.&lt;/p&gt; &lt;p&gt;If you want to create a &lt;a href="https://docs.openshift.com/container-platform/4.2/networking/routes/route-configuration.html" target="_blank" rel="noopener noreferrer"&gt;Route&lt;/a&gt; resource when the project is running in OpenShift and an &lt;a href="https://kubernetes.io/docs/concepts/services-networking/ingress" target="_blank" rel="noopener noreferrer"&gt;Ingress&lt;/a&gt; (instead of, for example, only if it is running in the Minikube), then we should be checking whether the specific &lt;a href="https://docs.okd.io/latest/rest_api/apis-route.openshift.io/v1.Route.html" target="_blank" rel="noopener noreferrer"&gt;v1.Route&lt;/a&gt; is installed or not.&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;How to implement this approach&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s start by creating the discovery client:&lt;/p&gt; &lt;pre&gt; // Get a config to talk to the apiserver cfg, err := config.GetConfig() if err != nil { log.Error(err, "") os.Exit(1) } // Create the discoveryClient discoveryClient, err := discovery.NewDiscoveryClientForConfig(cfg) if err != nil { log.Error(err, "Unable to create discovery client") os.Exit(1) }&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;cfg *rest.Config&lt;/code&gt; is created in the &lt;code&gt;main.go&lt;/code&gt;, by default in all projects built with &lt;a href="https://github.com/operator-framework/operator-sdk" target="_blank" rel="noopener noreferrer"&gt;Operator-SDK&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Now, we can search for all API resources as follows:&lt;/p&gt; &lt;pre&gt; // Get a list of all API's on the cluster apiGroup, apiResourceList , err := discoveryClient.ServerGroupsAndResources() if err != nil { log.Error(err, "Unable to get Group and Resources") os.Exit(1) }&lt;/pre&gt; &lt;p&gt;Note that by using the &lt;code&gt;kubectl api-resources&lt;/code&gt; command, it is possible to check the resources available in the cluster as follows:&lt;/p&gt; &lt;pre&gt;$ kubectl api-resources NAME SHORTNAMES APIGROUP NAMESPACED KIND bindings true Binding componentstatuses cs false ComponentStatus configmaps cm true ConfigMap endpoints ep true Endpoints events ev true Event limitranges limits true LimitRange namespaces ns false Namespace nodes no false Node persistentvolumeclaims pvc true PersistentVolumeClaim persistentvolumes pv false PersistentVolume pods po true Pod podtemplates true PodTemplate replicationcontrollers rc true ReplicationController resourcequotas quota true ResourceQuota secrets true Secret serviceaccounts sa true ServiceAccount services svc true Service mutatingwebhookconfigurations admissionregistration.k8s.io false MutatingWebhookConfiguration validatingwebhookconfigurations admissionregistration.k8s.io false ValidatingWebhookConfiguration customresourcedefinitions crd,crds apiextensions.k8s.io false CustomResourceDefinition apiservices apiregistration.k8s.io false APIService ...&lt;/pre&gt; &lt;p&gt;Now, we can check and verify if the resource is or is not on the cluster:&lt;/p&gt; &lt;pre&gt; // Looking for group.Name = "apiextensions.k8s.io" for i := 0; i &amp;#60; len(apiGroup); i++ { if apiGroup[i].Name == name { // found the api } }&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; It is possible to use other attributes, such as the &lt;code&gt;Group&lt;/code&gt;, &lt;code&gt;Version&lt;/code&gt;, and &lt;code&gt;Kind&lt;/code&gt;. For further information, check the &lt;a href="https://godoc.org/k8s.io/apimachinery/pkg/apis/meta/v1#APIGroup" target="_blank" rel="noopener noreferrer"&gt;APIGroup&lt;/a&gt; GoDoc.&lt;/p&gt; &lt;p&gt;It is possible to use the result of &lt;code&gt;apiResourceList&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; // Looking for Kind = "PersistentVolume" for i := 0; i &amp;#60; len(apiResourceList); i++ { if apiResourceList[i].Kind == kind { // found the Kind } }&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Check the &lt;a href="https://godoc.org/k8s.io/apimachinery/pkg/apis/meta/v1#APIResourceList" target="_blank" rel="noopener noreferrer"&gt;APIResourceList&lt;/a&gt; GoDoc to see other options.&lt;/p&gt; &lt;h2&gt;How to get the cluster version information&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s follow a code implementation as an example that can be used to get the cluster version by using the &lt;a href="https://godoc.org/k8s.io/client-go/discovery#DiscoveryClient" target="_blank" rel="noopener noreferrer"&gt;DiscoveryClient&lt;/a&gt; as well:&lt;/p&gt; &lt;pre&gt;// getClusterVersion will create and use an DiscoveryClient // to return the cluster version. // More info: https://godoc.org/k8s.io/client-go/discovery#DiscoveryClient func getClusterVersion(cfg *rest.Config) string { discoveryClient, err := discovery.NewDiscoveryClientForConfig(cfg) if err != nil { log.Error(err, "Unable to create discovery client") os.Exit(1) } sv, err := discoveryClient.ServerVersion() if err != nil { log.Error(err, "Unable to get server version") os.Exit(1) } return sv.String() }&lt;/pre&gt; &lt;p&gt;Keep in mind that these ideas can be beneficial and allow you to manage your solutions dynamically and programmatically. See that they can be also useful to handle issues on specific scenarios as well. An then, used beyond the installation and configuration process.&lt;/p&gt; &lt;p&gt;Also, before finishing, I&amp;#8217;d like to thank @Joe Lanford and @Jeff McCormick, who collaborated and provided feedback and input for this article.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Fwhy-not-couple-an-operators-logic-to-a-specific-kubernetes-platform%2F&amp;#38;linkname=Why%20not%20couple%20an%20Operator%E2%80%99s%20logic%20to%20a%20specific%20Kubernetes%20platform%3F" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Fwhy-not-couple-an-operators-logic-to-a-specific-kubernetes-platform%2F&amp;#38;linkname=Why%20not%20couple%20an%20Operator%E2%80%99s%20logic%20to%20a%20specific%20Kubernetes%20platform%3F" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Fwhy-not-couple-an-operators-logic-to-a-specific-kubernetes-platform%2F&amp;#38;linkname=Why%20not%20couple%20an%20Operator%E2%80%99s%20logic%20to%20a%20specific%20Kubernetes%20platform%3F" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Fwhy-not-couple-an-operators-logic-to-a-specific-kubernetes-platform%2F&amp;#38;linkname=Why%20not%20couple%20an%20Operator%E2%80%99s%20logic%20to%20a%20specific%20Kubernetes%20platform%3F" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Fwhy-not-couple-an-operators-logic-to-a-specific-kubernetes-platform%2F&amp;#38;linkname=Why%20not%20couple%20an%20Operator%E2%80%99s%20logic%20to%20a%20specific%20Kubernetes%20platform%3F" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Fwhy-not-couple-an-operators-logic-to-a-specific-kubernetes-platform%2F&amp;#38;linkname=Why%20not%20couple%20an%20Operator%E2%80%99s%20logic%20to%20a%20specific%20Kubernetes%20platform%3F" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Fwhy-not-couple-an-operators-logic-to-a-specific-kubernetes-platform%2F&amp;#38;linkname=Why%20not%20couple%20an%20Operator%E2%80%99s%20logic%20to%20a%20specific%20Kubernetes%20platform%3F" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F22%2Fwhy-not-couple-an-operators-logic-to-a-specific-kubernetes-platform%2F&amp;#038;title=Why%20not%20couple%20an%20Operator%E2%80%99s%20logic%20to%20a%20specific%20Kubernetes%20platform%3F" data-a2a-url="https://developers.redhat.com/blog/2020/01/22/why-not-couple-an-operators-logic-to-a-specific-kubernetes-platform/" data-a2a-title="Why not couple an Operator’s logic to a specific Kubernetes platform?"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/22/why-not-couple-an-operators-logic-to-a-specific-kubernetes-platform/"&gt;Why not couple an Operator&amp;#8217;s logic to a specific Kubernetes platform?&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Ie5nCx_LiUA" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;You might find yourself in situations where you believe that a logic implementation should occur only if and when your Operator is running on a specific Kubernetes platform. So, you probably want to know how to get the cluster vendor from the operator. In this article, we will discuss why relying on the vendor is [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/22/why-not-couple-an-operators-logic-to-a-specific-kubernetes-platform/"&gt;Why not couple an Operator&amp;#8217;s logic to a specific Kubernetes platform?&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">666287</post-id><dc:creator>Camila Macedo</dc:creator><dc:date>2020-01-22T08:00:09Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/22/why-not-couple-an-operators-logic-to-a-specific-kubernetes-platform/</feedburner:origLink></entry><entry><title>First steps with the data virtualization Operator for Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/P8HJ75zQnwo/" /><category term="Containers" /><category term="DevOps" /><category term="Operator" /><category term="Data Integration" /><category term="Data Virtualization" /><category term="Kubernetes" /><category term="OpenShift Operator" /><category term="Red Hat Integration" /><author><name>Bilgin Ibryam</name></author><id>https://developers.redhat.com/blog/?p=664397</id><updated>2020-01-21T08:00:41Z</updated><published>2020-01-21T08:00:41Z</published><content type="html">&lt;p&gt;The Red Hat Integration &lt;a href="https://www.redhat.com/en/blog/whats-new-red-hat-integration" target="_blank" rel="noopener noreferrer"&gt;Q4 release&lt;/a&gt; adds many new features and capabilities with an increasing focus around cloud-native data integration. The features I&amp;#8217;m most excited about are the introduction of the &lt;a href="https://developers.redhat.com/blog/2019/11/26/red-hat-simplifies-transition-to-open-source-kafka-with-new-service-registry-and-http-bridge/"&gt;schema registry&lt;/a&gt;, the advancement of change data capture capabilities based on &lt;a href="https://developers.redhat.com/blog/2019/11/22/red-hat-advances-debezium-cdc-connectors-for-apache-kafka-support-to-technical-preview/"&gt;Debezium to technical preview&lt;/a&gt;, and data virtualization (technical preview) capabilities.&lt;/p&gt; &lt;p&gt;Data integration is a topic that has not received much attention from the cloud-native community so far, and we will cover it in more detail in future posts. Here, we jump straight into demonstrating the latest release of &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_integration/2019-12/html-single/data_virtualization/index" target="_blank" rel="noopener noreferrer"&gt;data virtualization&lt;/a&gt; (DV) capabilities on &lt;a href="https://developers.redhat.com/openshift/" target="_blank" rel="noopener noreferrer"&gt;Red Hat OpenShift&lt;/a&gt; 4. This is a step-by-step visual tutorial describing how to create a simple virtual database using Red Hat Integration&amp;#8217;s data virtualization Operator. By the end of the tutorial, you will learn:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;How to deploy the DV Operator.&lt;/li&gt; &lt;li&gt;How to create a virtual database.&lt;/li&gt; &lt;li&gt;How to access the virtual database.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The steps throughout this article work on any Openshift 4.x environment with operator support, even on time- and resource-constrained environments such as the &lt;a href="https://learn.openshift.com/" target="_blank" rel="noopener noreferrer"&gt;Red Hat OpenShift Interactive Learning Portal&lt;/a&gt;.&lt;span id="more-664397"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Prepare the environment&lt;/h2&gt; &lt;p&gt;First, you need to prepare an environment for deploying the productized DV operator on OpenShift 4. If you are a Red Hat partner and have access to the Red Hat Product Demo System (RHPDS), request an OpenShift cluster of type &amp;#8220;OpenShift 4 Workshop&amp;#8221; from the Services menu, as shown in Figure 1. A simple cluster of one node (five users) should be enough:&lt;/p&gt; &lt;div id="attachment_664417" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bf78aa256.png"&gt;&lt;img aria-describedby="caption-attachment-664417" class="wp-image-664417 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bf78aa256-1024x448.png" alt="The RHDPS Services screen with &amp;#34;OpenShift 4 Workshop&amp;#34; selected." width="640" height="280" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bf78aa256-1024x448.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bf78aa256-300x131.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bf78aa256-768x336.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664417" class="wp-caption-text"&gt;Figure 1: In the RHPDS, go to Services and select &lt;em&gt;OpenShift 4 Workshop&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;ALTERNATIVE&lt;/strong&gt;: Whether you are a partner or not, if you do not have access to RHPDS, the same steps also work on &lt;a href="https://learn.openshift.com/"&gt;the &lt;/a&gt;&lt;a href="https://learn.openshift.com/" target="_blank" rel="noopener noreferrer"&gt;Red Hat OpenShift Interactive Learning Portal&lt;/a&gt;. There, you get a resource- and time-constrained OpenShift cluster for one hour. In this environment, choose &lt;em&gt;OpenShift 4.2 Playground&lt;/em&gt; and follow the same steps (and don&amp;#8217;t forget to type fast). The rest of this guide assumes RHPDS as the environment.&lt;/p&gt; &lt;p&gt;Now, to create the &lt;code&gt;dv-demo&lt;/code&gt; project.&lt;/p&gt; &lt;h3&gt;In the GUI&lt;/h3&gt; &lt;p&gt;Once the OpenShift cluster is set up, log into OpenShift and go to the Projects page, as shown in Figure 2:&lt;/p&gt; &lt;div id="attachment_664427" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bfbecb1b1.png"&gt;&lt;img aria-describedby="caption-attachment-664427" class="wp-image-664427 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bfbecb1b1-1024x797.png" alt="The OpenShift Projects page." width="640" height="498" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bfbecb1b1-1024x797.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bfbecb1b1-300x234.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bfbecb1b1-768x598.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0bfbecb1b1.png 1030w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664427" class="wp-caption-text"&gt;Figure 2: Create your new project from the OpenShift Projects page.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Create a new project named &lt;code&gt;dv-demo&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;On the command line&lt;/h3&gt; &lt;p&gt;Alternatively, get your token and log in from the command line to create a new project called &lt;code&gt;dv-demo&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ oc login --token=YOUR_TOKEN --server=YOUR_SERVER $ oc new-project dv-demo&lt;/pre&gt; &lt;p&gt;Then, execute all of the following operations in the &lt;code&gt;dv-demo&lt;/code&gt; namespace. Create a Secret using your Red Hat Customer Portal credentials to get access to the Red Hat container images:&lt;/p&gt; &lt;pre&gt;$ oc create secret docker-registry dv-pull-secret --docker-server=registry.redhat.io --docker-username=$RH_PORTAL_USERNAME --docker-password=$RH_PORTAL_PASSWORD --docker-email=$RH_PORTAL_EMAIL $ oc secrets link builder dv-pull-secret $ oc secrets link builder dv-pull-secret --for=pull&lt;/pre&gt; &lt;h2&gt;Deploy the DV operator&lt;/h2&gt; &lt;p&gt;The following steps deploy the DV operator:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Select&lt;em&gt; Catalog -&amp;#62; OperatorHub&lt;/em&gt; from the OpenShift menu.&lt;/li&gt; &lt;li&gt;Search for &amp;#8220;Data Virtualization.&amp;#8221;&lt;/li&gt; &lt;li&gt;Select the &lt;em&gt;Data Virtualization Operator&lt;/em&gt; 7.5.0 provided by Red Hat, Inc., as shown in Figure 3: &lt;div id="attachment_664437" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c01e17f91.png"&gt;&lt;img aria-describedby="caption-attachment-664437" class="wp-image-664437 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c01e17f91-1024x664.png" alt="" width="640" height="415" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c01e17f91-1024x664.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c01e17f91-300x195.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c01e17f91-768x498.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664437" class="wp-caption-text"&gt;Figure 3: The Data Virtualization Operator dialog box.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;b&gt;ALTERNATIVE: &lt;/b&gt;Data Virtualization Operator 7.5.0 provided by Red Hat, Inc., requires credentials to access the Red Hat Container Catalog. Instead, you can use the Teiid Community Operator, which is based on upstream container images. Its implementation does not require Red Hat credentials. This Operator is not supported by Red Hat, but it can be used for quick demo purposes.&lt;/li&gt; &lt;li&gt;Click&lt;em&gt; Install.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;Make sure the namespace is the same as the one created earlier and then click &lt;em&gt;Subscribe&lt;/em&gt;, as shown in Figure 4: &lt;p&gt;&lt;div id="attachment_664447" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c043cf990.png"&gt;&lt;img aria-describedby="caption-attachment-664447" class="wp-image-664447 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c043cf990-1024x933.png" alt="The Create Operator Subscription dialog box." width="640" height="583" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c043cf990-1024x933.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c043cf990-300x273.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c043cf990-768x700.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c043cf990.png 1026w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664447" class="wp-caption-text"&gt;Figure 4: The Create Operator Subscription dialog box.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 40px;"&gt;After a few minutes, you should see the DV Operator deployed as a pod in Running status, as shown in Figure 5:&lt;/p&gt; &lt;div id="attachment_664457" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c0c8a8241.png"&gt;&lt;img aria-describedby="caption-attachment-664457" class="wp-image-664457 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c0c8a8241-1024x477.png" alt="" width="640" height="298" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c0c8a8241-1024x477.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c0c8a8241-300x140.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c0c8a8241-768x358.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c0c8a8241.png 1461w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664457" class="wp-caption-text"&gt;Figure 5: The DV Operator as shown in the Pods listing.&lt;/p&gt;&lt;/div&gt; &lt;ol start="6"&gt; &lt;li&gt;Link the Secret created earlier with the &lt;code&gt;dv-operator&lt;/code&gt; service account so that the DV Operator can pull images from the Red Hat registry, too. This step should be performed &lt;em&gt;after&lt;/em&gt; the operator is installed and the service account created, and before creating a new VirtualDatabase CustomResource (CR): &lt;pre&gt;$ oc secrets link dv-operator dv-pull-secret --for=pull&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;With that, the operator installation process is complete and ready for creating virtualizations.&lt;/p&gt; &lt;h2&gt;Create a sample database&lt;/h2&gt; &lt;p&gt;Before creating a virtualization, we need a sample database populated with data. The following script installs a PostgreSQL database and inserts sample data. If you are going to create a virtualization to an existing database, instead, you can skip this step and go to the next section:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a PostgreSQL database: &lt;pre&gt;$ oc new-app \ -e POSTGRESQL_USER=user \ -e POSTGRESQL_PASSWORD=mypassword \ -e POSTGRESQL_DATABASE=sampledb \ postgresql:9.6&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Once the PostgreSQL pod is in Running status, connect to it and run the &lt;code&gt;psql&lt;/code&gt; client: &lt;pre&gt;$ oc rsh $(oc get pods -o name -l app=postgresql) $ psql -U user sampledb&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Create a few tables and populate them with data: &lt;pre&gt;CREATE TABLE CUSTOMER ( ID bigint, SSN char(25), NAME varchar(64), CONSTRAINT CUSTOMER_PK PRIMARY KEY(ID)); CREATE TABLE ADDRESS ( ID bigint, STREET char(25), ZIP char(10), CUSTOMER_ID bigint, CONSTRAINT ADDRESS_PK PRIMARY KEY(ID), CONSTRAINT CUSTOMER_FK FOREIGN KEY (CUSTOMER_ID) REFERENCES CUSTOMER (ID)); INSERT INTO CUSTOMER (ID,SSN,NAME) VALUES (10, 'CST01002','Joseph Smith'); INSERT INTO CUSTOMER (ID,SSN,NAME) VALUES (11, 'CST01003','Nicholas Ferguson'); INSERT INTO CUSTOMER (ID,SSN,NAME) VALUES (12, 'CST01004','Jane Aire'); INSERT INTO ADDRESS (ID, STREET, ZIP, CUSTOMER_ID) VALUES (10, 'Main St', '12345', 10); \q exit&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;With that, we have a simple database set up with data and ready for our demo.&lt;/p&gt; &lt;h2&gt;Create a virtual database&lt;/h2&gt; &lt;p&gt;We now have our operator installed and a sample database populated. We are all set to create a virtualization. Here are a few ways to do it.&lt;/p&gt; &lt;h3&gt;The simplest approach&lt;/h3&gt; &lt;p&gt;For this purpose, we will use the simplest approach where the data description language (DDL) definition is embedded in the CR itself. For other approaches, where the DDL and its dependencies are retrieved from external locations, check out the &amp;#8220;Next steps&amp;#8221; section at the end of this document:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;From the OpenShift menu, select &lt;strong&gt;Catalog&lt;/strong&gt; -&amp;#62; &lt;strong&gt;Installed Operators&lt;/strong&gt; as shown in Figure 6:&lt;i&gt;&lt;i&gt;&lt;/i&gt;&lt;/i&gt;&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_664467" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c104b173c.png"&gt;&lt;img aria-describedby="caption-attachment-664467" class="wp-image-664467 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c104b173c-300x240.png" alt="OpenShift's Catalog -&amp;#62; Install Operators dialog box." width="300" height="240" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c104b173c-300x240.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c104b173c-768x615.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c104b173c.png 949w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664467" class="wp-caption-text"&gt;Figure 6: OpenShift&amp;#8217;s &lt;strong&gt;Catalog&lt;/strong&gt; -&amp;#62; &lt;strong&gt;Install&lt;/strong&gt; Operators dialog box.&lt;/p&gt;&lt;/div&gt; &lt;ol start="2"&gt; &lt;li&gt;Select &lt;strong&gt;Data Virtualization Operator&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Select the &lt;strong&gt;Virtual Database&lt;/strong&gt; tab.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Create Virtual Database&lt;/strong&gt;, which opens the &lt;strong&gt;Create Virtual Database&lt;/strong&gt; dialog box shown in Figure 7:&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_664487" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c17be532e.png"&gt;&lt;img aria-describedby="caption-attachment-664487" class="wp-image-664487 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c17be532e-1024x811.png" alt="The Create Virtual Database dialog box." width="640" height="507" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c17be532e-1024x811.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c17be532e-300x238.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c17be532e-768x608.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c17be532e.png 1145w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664487" class="wp-caption-text"&gt;Figure 7: The &lt;strong&gt;Create Virtual Database&lt;/strong&gt; dialog box.&lt;/p&gt;&lt;/div&gt; &lt;ol start="5"&gt; &lt;li&gt;Inspect and modify the example CR that defines the data virtualization.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The essence of virtualization is the DDL definition that creates new abstract data layers on top of the physical data layers using SQL-MED specification. Here is a brief explanation of the example:&lt;/p&gt; &lt;pre&gt;//Step 1 Defines a name for the virtual database you want to create CREATE DATABASE customer OPTIONS (ANNOTATION 'Customer VDB');USE DATABASE customer; //Step 2: Configures a translator to interpret data from the datasource CREATE FOREIGN DATA WRAPPER postgresql; //Step 3: Configures the datasource connection details for the external source CREATE SERVER sampledb TYPE 'NONE' FOREIGN DATA WRAPPER postgresql; //Step 4: Creates schemas to hold metadata about the source and virtual layers CREATE SCHEMA accounts SERVER sampledb; CREATE VIRTUAL SCHEMA portfolio; //Step 5: Imports the metadata from source schema into a virtual schema SET SCHEMA accounts; IMPORT FOREIGN SCHEMA public FROM SERVER sampledb INTO accounts OPTIONS("importer.useFullSchemaName" 'false'); // Step 6: Create virtual views SET SCHEMA portfolio; CREATE VIEW CustomerZip(id bigint PRIMARY KEY, name string, ssn string, zip string) AS    SELECT c.ID as id, c.NAME as name, c.SSN as ssn, a.ZIP as zip FROM accounts.CUSTOMER c LEFT OUTER JOIN accounts.ADDRESS a ON c.ID = a.CUSTOMER_ID;&lt;/pre&gt; &lt;p&gt;To read more about these constructs, check out the data virtualization &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_integration/2019-12/html-single/data_virtualization/index" target="_blank" rel="noopener noreferrer"&gt;guide&lt;/a&gt;.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;ALTERNATIVE&lt;i&gt;: &lt;/i&gt;&lt;/b&gt;Before creating the virtual database, you can customize the CR containing the details of the virtualization and the embedded DDL. In the example CR above, the connection details are hardcoded and match with those of the PostgreSQL database created earlier. If you just want to get this example running, don’t edit anything and hit the &lt;strong&gt;Create&lt;/strong&gt; button. If you prefer to retrieve the PostgreSQL connection details from a Kubernetes Secret object rather than hard-coding them in the CR, see the section &amp;#8220;Using a Kubernetes Secret object instead.&amp;#8221;&lt;/p&gt; &lt;h3&gt;Using a Kubernetes Secret object instead&lt;/h3&gt; &lt;p&gt;To use a Kubernetes Secret object:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a Secret that will be used to access the database from the virtualization:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;oc create -f - &amp;#60;&amp;#60;EOF apiVersion: v1 kind: Secret metadata: name: postgresql type: Opaque stringData: database-user: user databse-name: sampledb database-password: mypassword EOF&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;In the CR, replace:&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 40px;"&gt;- name: SPRING_DATASOURCE_SAMPLEDB_USERNAME value: user - name: SPRING_DATASOURCE_SAMPLEDB_PASSWORD value: mypassword - name: SPRING_DATASOURCE_SAMPLEDB_DATABASENAME value: sampledb&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;with:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;- name: SPRING_DATASOURCE_SAMPLEDB_USERNAME valueFrom: secretKeyRef: name: postgresql key: database-user - name: SPRING_DATASOURCE_SAMPLEDB_PASSWORD valueFrom: secretKeyRef: name: postgresql key: database-password - name: SPRING_DATASOURCE_SAMPLEDB_DATABASENAME valueFrom: secretKeyRef: name: postgresql key: database-name&lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;Hit the &lt;strong&gt;Create&lt;/strong&gt; button to instantiate the virtualization, as shown in Figure 8:&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_664497" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c27038ac2.png"&gt;&lt;img aria-describedby="caption-attachment-664497" class="wp-image-664497 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c27038ac2-1024x768.png" alt="Creating the alternative virtual database." width="640" height="480" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c27038ac2-1024x768.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c27038ac2-300x225.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c27038ac2-768x576.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c27038ac2.png 1179w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664497" class="wp-caption-text"&gt;Figure 8: Creating the alternative virtual database.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After a few minutes, you should see that in addition to the &lt;code&gt;dv-operator&lt;/code&gt; and &lt;code&gt;postgresql&lt;/code&gt; pods, there is also an &lt;code&gt;rdbms-springboot&lt;/code&gt;pod running our new virtualization. Once this pod is in Running status, we are ready to use our new virtualization, as you can see in Figure 9:&lt;/p&gt; &lt;div id="attachment_664507" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c2d598af2.png"&gt;&lt;img aria-describedby="caption-attachment-664507" class="wp-image-664507 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c2d598af2-1024x738.png" alt="" width="640" height="461" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c2d598af2-1024x738.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c2d598af2-300x216.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c2d598af2-768x553.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c2d598af2.png 1303w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664507" class="wp-caption-text"&gt;Figure 9: The &lt;code&gt;dv-operator&lt;/code&gt;, &lt;code&gt;postgresql&lt;/code&gt;, and &lt;code&gt;rdbms-springboot&lt;/code&gt; pods all running in the &lt;code&gt;dv-demo&lt;/code&gt; namespace.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Using the CLI&lt;/h3&gt; &lt;p&gt;Virtualizations can be created not only from the OpenShift console as demonstrated in the previous section but also through the command line as part of the CI/CD process. You can create a similar virtualization (named &lt;code&gt;dv-customer&lt;/code&gt;) with one CLI command as follows:&lt;/p&gt; &lt;pre&gt;$ oc create -f https://raw.githubusercontent.com/teiid/teiid-openshift-examples/master/rdbms-example/vdb-in-operator/dv-customer.yaml&lt;/pre&gt; &lt;p&gt;In the end, you can mix and match your methods. Create your virtualization through CLI and then manage them from OpenShift console, or the other way around. Once done, you can also delete the virtualization within the CLI like this:&lt;/p&gt; &lt;pre&gt;$ oc delete vdb dv-customer&lt;/pre&gt; &lt;h2&gt;Access the virtual database&lt;/h2&gt; &lt;p&gt;In addition to deploying virtualization, the DV Operator also creates a service and a route for exposing various virtual database endpoints.&lt;/p&gt; &lt;h3&gt;Access from inside the cluster&lt;/h3&gt; &lt;p&gt;To see what protocols are exposed through the service, go to the OpenShift menu and select &lt;strong&gt;Networking&lt;/strong&gt; -&amp;#62; &lt;strong&gt;Services&lt;/strong&gt;. Then, choose the service named &lt;code&gt;rdbms-springboot&lt;/code&gt;, as shown in Figure 10:&lt;/p&gt; &lt;div id="attachment_664517" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c30fdd7d5.png"&gt;&lt;img aria-describedby="caption-attachment-664517" class="wp-image-664517 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c30fdd7d5-1024x640.png" alt="The rdbms-springboot service overview window." width="640" height="400" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c30fdd7d5-1024x640.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c30fdd7d5-300x188.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c30fdd7d5-768x480.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664517" class="wp-caption-text"&gt;Figure 10: The &lt;code&gt;rdbms-springboot&lt;/code&gt; service overview window.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;All of the ports named here are accessible from inside the OpenShift cluster; for example, from other pods that want to use the virtualization. Here we can see the following endpoints listed:&lt;/p&gt; &lt;ul&gt; &lt;li style="list-style-type: none;"&gt; &lt;ul&gt; &lt;li&gt;Monitoring data exposed through Jolokia and Prometheus ports.&lt;/li&gt; &lt;li&gt;OData and OpenAPI exposed over the HTTP port.&lt;/li&gt; &lt;li&gt;JDBC access available as a Teiid port.&lt;/li&gt; &lt;li&gt;ODBC access available as a PostgreSQL (&lt;code&gt;pg&lt;/code&gt;) port.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;HTTP access from outside the cluster&lt;/h3&gt; &lt;p&gt;The simplest way to access the virtualization from outside of the OpenShift cluster is through HTTP and OData/OpenAPI. To find the created route, go to the OpenShift menu and select &lt;em&gt;Networking -&amp;#62; Routes,&lt;/em&gt; and choose the route named after the virtualization &lt;code&gt;rdbms-springboot&lt;/code&gt; as shown in Figure 11:&lt;/p&gt; &lt;div id="attachment_664527" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c39f320c0.png"&gt;&lt;img aria-describedby="caption-attachment-664527" class="wp-image-664527 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c39f320c0-1024x653.png" alt="The rdbms-springboot route in the OpenShift interface." width="640" height="408" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c39f320c0-1024x653.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c39f320c0-300x191.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/img_5df0c39f320c0-768x489.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-664527" class="wp-caption-text"&gt;Figure 11: The &lt;code&gt;rdbms-springboot&lt;/code&gt; route.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Clicking on the location will give you &amp;#8220;404 &amp;#8211; Not found,&amp;#8221; as there is no endpoint exposed at &amp;#8220;/&amp;#8221;. To see the OData metadata, append &lt;code&gt;odata/$metadata&lt;/code&gt; to the end of the URL (for example, &lt;code&gt;https://rdbms-springboot-dv-demo.example.com/odata/$metadata&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;If you don’t want to edit the URL and want to directly access the OData endpoint, go to the OpenShift menu and select &lt;em&gt;Installed Operator -&amp;#62; DV Operator -&amp;#62; Virtual Databases -&amp;#62; rdbms-springboot&lt;/em&gt; and then route link.&lt;/p&gt; &lt;p&gt;Try out other queries based on the &lt;a href="https://www.odata.org/getting-started/basic-tutorial/" target="_blank" rel="noopener noreferrer"&gt;OData Basic Tutorial&lt;/a&gt; such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Retrieve top 2 customer records ordered by name:&lt;br /&gt; &lt;code&gt;https://rdbms-springboot-dv-demo.example.com/odata/portfolio/CustomerZip?$top=2&amp;#38;$orderby=name&lt;/code&gt;&lt;em&gt;&lt;br /&gt; &lt;/em&gt;&lt;/li&gt; &lt;li&gt;Retrieve a customer record by ID and pick the name field value:&lt;br /&gt; &lt;code&gt;https://rdbms-springboot-dv-demo.example.com/odata/portfolio/CustomerZip(10)/name/$value&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Search customer records by name, and display the result in JSON:&lt;br /&gt; &lt;code&gt;https://rdbms-springboot-dv-demo.example.com/odata/portfolio/CustomerZip?$filter=startswith(name,%27Joseph%27)&amp;#38;$format=JSON&lt;/code&gt;&lt;em&gt;&lt;br /&gt; &lt;/em&gt;&lt;/li&gt; &lt;li&gt;Generate OpenAPI v3 schema from OData metadata&lt;br /&gt; &lt;code&gt;https://rdbms-springboot-dv-demo.example.com/odata/openapi.json?version=3&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;JDBC/ODBC access from outside the cluster&lt;/h3&gt; &lt;p&gt;To access the virtualizations over JDBC/ODBC from outside of the OpenShift cluster, we have to expose the JDBC/ODBC ports to the outside world. Then, we can use an SQL client supporting these protocols, or use this Spring Boot-based &lt;a href="https://github.com/bibryam/teiid-examples/tree/master/client" target="_blank" rel="noopener noreferrer"&gt;client application&lt;/a&gt;.&lt;/p&gt; &lt;h4&gt;The simplest way&lt;/h4&gt; &lt;p&gt;The simplest way to expose JDBC/ODBC ports for development purposes (specifically) is by using the &lt;code&gt;oc&lt;/code&gt; client as follows:&lt;/p&gt; &lt;pre&gt;$ oc port-forward $(oc get pods -o=jsonpath='{.items[0].metadata.name}' -l app=rdbms-springboot) 35432 31000&lt;/pre&gt; &lt;p&gt;This command maps ports 35432 (ODBC/PG) and 31000 (Teiid JDBC) from the pod with label &lt;code&gt;rdbms-springboot&lt;/code&gt; to the local machine. While this command is running in the terminal, you can start an application and connect to it with configurations such as:&lt;/p&gt; &lt;pre&gt;jdbc:postgresql://127.0.0.1:35432/customer?sslMode=disable&lt;/pre&gt; &lt;p&gt;or&lt;/p&gt; &lt;pre&gt;jdbc:teiid:customer@mm://127.0.0.1:31000&lt;/pre&gt; &lt;h4&gt;Create a Kubernetes LoadBalancer service&lt;/h4&gt; &lt;p&gt;Another way to expose the same port is by creating a Kubernetes LoadBalancer service that can be customized with sticky sessions, etc. To create the LoadBalancer service, execute the following:&lt;/p&gt; &lt;pre&gt;$ oc apply -f - &amp;#60;&amp;#60; EOF apiVersion: v1 kind: Service metadata:   name: rdbms-springboot-expose spec:   type: LoadBalancer   ports:   - name: teiid     port: 31000    - name: pg     port: 35432             selector:     app: rdbms-springboot EOF&lt;/pre&gt; &lt;p&gt;Once the service is created, you can discover the full URL to access the LoadBalance for your cluster and infrastructure provider with the following query:&lt;/p&gt; &lt;pre&gt;$ oc get svc rdbms-springboot-expose -o=jsonpath='{..ingress[0].hostname}'&lt;/pre&gt; &lt;p&gt;For my OpenShift cluster, the command returns the following URL:&lt;/p&gt; &lt;pre&gt;A4d3bf5fd1b9311eab2b602474b8b0b4-143190945.eu-central-1.elb.amazonaws.com&lt;/pre&gt; &lt;p&gt;This URL can be used by the sample program above, or any other tool, as follows:&lt;/p&gt; &lt;pre&gt;jdbc:postgresql://a4d3bf5fd1b9311eab2b602474b8b0b4-143190945.eu-central-1.elb.amazonaws.com:35432/customer?sslMode=disable&lt;/pre&gt; &lt;p&gt;or&lt;/p&gt; &lt;pre&gt;jdbc:teiid:customer@mm://a4d3bf5fd1b9311eab2b602474b8b0b4-143190945.eu-central-1.elb.amazonaws.com:31000&lt;/pre&gt; &lt;p&gt;The above mechanisms give easy access from outside of the OpenShift cluster to the running virtualizations. There are other mechanisms too, but these are enough for a getting started experience.&lt;/p&gt; &lt;h2&gt;Next steps&lt;/h2&gt; &lt;p&gt;Congratulations, you have reached the end of how to get started with the data virtualization Operator for OpenShift. Data virtualization is an essential part of the Red Hat Integration stack and we will cover how it integrates with other Red Hat technologies in future pieces. To find out more about data virtualization, try out our &lt;a href="https://github.com/teiid/teiid-openshift-examples" target="_blank" rel="noopener noreferrer"&gt;examples&lt;/a&gt; and check out the latest Red Hat Integration &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_integration/2019-12/" target="_blank" rel="noopener noreferrer"&gt;documentation&lt;/a&gt; on how to configure data virtualization with other data sources and secure its endpoints through 3scale.&lt;/p&gt; &lt;p&gt;If you have requests or questions related to running the data virtualization technical preview, please let us know by sending an email to the &lt;a href="mailto:data-integration-preview@redhat.com" target="_blank" rel="noopener noreferrer"&gt;data-integration-preview mailing list&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F21%2Ffirst-steps-with-the-data-virtualization-operator-for-red-hat-openshift%2F&amp;#38;linkname=First%20steps%20with%20the%20data%20virtualization%20Operator%20for%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F21%2Ffirst-steps-with-the-data-virtualization-operator-for-red-hat-openshift%2F&amp;#38;linkname=First%20steps%20with%20the%20data%20virtualization%20Operator%20for%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F21%2Ffirst-steps-with-the-data-virtualization-operator-for-red-hat-openshift%2F&amp;#38;linkname=First%20steps%20with%20the%20data%20virtualization%20Operator%20for%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F21%2Ffirst-steps-with-the-data-virtualization-operator-for-red-hat-openshift%2F&amp;#38;linkname=First%20steps%20with%20the%20data%20virtualization%20Operator%20for%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F21%2Ffirst-steps-with-the-data-virtualization-operator-for-red-hat-openshift%2F&amp;#38;linkname=First%20steps%20with%20the%20data%20virtualization%20Operator%20for%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F21%2Ffirst-steps-with-the-data-virtualization-operator-for-red-hat-openshift%2F&amp;#38;linkname=First%20steps%20with%20the%20data%20virtualization%20Operator%20for%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F21%2Ffirst-steps-with-the-data-virtualization-operator-for-red-hat-openshift%2F&amp;#38;linkname=First%20steps%20with%20the%20data%20virtualization%20Operator%20for%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F21%2Ffirst-steps-with-the-data-virtualization-operator-for-red-hat-openshift%2F&amp;#038;title=First%20steps%20with%20the%20data%20virtualization%20Operator%20for%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2020/01/21/first-steps-with-the-data-virtualization-operator-for-red-hat-openshift/" data-a2a-title="First steps with the data virtualization Operator for Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/21/first-steps-with-the-data-virtualization-operator-for-red-hat-openshift/"&gt;First steps with the data virtualization Operator for Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/P8HJ75zQnwo" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The Red Hat Integration Q4 release adds many new features and capabilities with an increasing focus around cloud-native data integration. The features I&amp;#8217;m most excited about are the introduction of the schema registry, the advancement of change data capture capabilities based on Debezium to technical preview, and data virtualization (technical preview) capabilities. Data integration is a [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/21/first-steps-with-the-data-virtualization-operator-for-red-hat-openshift/"&gt;First steps with the data virtualization Operator for Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">664397</post-id><dc:creator>Bilgin Ibryam</dc:creator><dc:date>2020-01-21T08:00:41Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/21/first-steps-with-the-data-virtualization-operator-for-red-hat-openshift/</feedburner:origLink></entry><entry><title>MIR: A lightweight JIT compiler project</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PDvpKffeLA8/" /><category term="C" /><category term="clang/LLVM" /><category term="Performance" /><category term="Ruby" /><category term="CRuby" /><category term="JIT compiler" /><category term="MIR" /><category term="optimization" /><author><name>Vladimir Makarov</name></author><id>https://developers.redhat.com/blog/?p=664687</id><updated>2020-01-20T08:00:32Z</updated><published>2020-01-20T08:00:32Z</published><content type="html">&lt;p&gt;For the past three years, I&amp;#8217;ve been participating in adding just-in-time compilation (&lt;a href="https://en.wikipedia.org/wiki/Just-in-time_compilation" target="_blank" rel="noopener noreferrer"&gt;JIT&lt;/a&gt;) to &lt;a href="https://github.com/ruby/ruby" target="_blank" rel="noopener noreferrer"&gt;CRuby&lt;/a&gt;. Now, CRuby has the &lt;a href="https://www.rubyguides.com/2018/11/ruby-mjit/"&gt;method-based just-in-time compiler (MJIT)&lt;/a&gt;, which improves performance for non-input/output-bound programs.&lt;/p&gt; &lt;p&gt;The most popular approach to implementing a JIT is to use &lt;a href="https://llvm.org" target="_blank" rel="noopener noreferrer"&gt;LLVM&lt;/a&gt; or &lt;a href="https://gcc.gnu.org/" target="_blank" rel="noopener noreferrer"&gt;GCC&lt;/a&gt; JIT interfaces, like &lt;a href="https://llvm.org/docs/ORCv2.html" target="_blank" rel="noopener noreferrer"&gt;ORC&lt;/a&gt; or &lt;a href="https://gcc.gnu.org/onlinedocs/jit/" target="_blank" rel="noopener noreferrer"&gt;LibGCCJIT&lt;/a&gt;. GCC and LLVM developers spend huge effort to implement the optimizations reliably, effectively, and to work on a lot of targets. Using LLVM or GCC to implement JIT, we can just utilize these optimizations for free. Using the existing compilers was the only way to get JIT for CRuby in the short time before the Ruby 3.0 release, which has the goal of &lt;a href="https://blog.heroku.com/ruby-3-by-3" target="_blank" rel="noopener noreferrer"&gt;improving CRuby performance by three times&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;So, CRuby MJIT utilizes GCC or LLVM, but what is unique about this JIT?&lt;span id="more-664687"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;MJIT does not use existing compiler JIT interfaces. Instead, it uses C as an interface language without losing compilation speed. Practically the same compilation speed as with the existing JIT interfaces is achieved by using &lt;a href="https://en.wikipedia.org/wiki/Precompiled_header" target="_blank" rel="noopener noreferrer"&gt;precompiled headers&lt;/a&gt; and a memory filesystem.&lt;/p&gt; &lt;p&gt;Choosing C as a JIT interface language significantly simplifies JIT implementation, maintenance, and debugging. Doing so also makes the JIT independent from a particular C compiler. Precompiled headers are a pretty standard feature of modern C/C++ compilers.&lt;/p&gt; &lt;h2 id="disadvantages-of-gccllvm-based-jit"&gt;Disadvantages of GCC/LLVM-based JIT&lt;/h2&gt; &lt;p&gt;Enough about the advantages of GCC/LLVM-based JITs. Let us speak about the disadvantages:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;GCC/LLVM-based JITs are big.&lt;/li&gt; &lt;li&gt;Their compilation speed can be slow.&lt;/li&gt; &lt;li&gt;It is hard to implement combined optimizations of code written in different programming languages.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Regarding the last point, in the case of CRuby, Ruby and C must be optimized together as you can be using implementation languages of different Ruby methods. Let us consider these disadvantages in more detail.&lt;/p&gt; &lt;h3 id="disadvantages-of-gccllvm-based-jit"&gt;GCC/LLVM size&lt;/h3&gt; &lt;p&gt;First of all, GCC and LLVM are big compared to CRuby. How big? If we ask &lt;a href="https://dwheeler.com/sloccount" target="_blank" rel="noopener noreferrer"&gt;SLOCCount&lt;/a&gt;, GCC and LLVM sources are about three times larger than CRuby, as shown in Figure 1. CRuby is already a big project by itself, with its source consisting of more than 1.5 million lines of code:&lt;/p&gt; &lt;div id="attachment_664837" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664837" class="wp-image-664837 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/sloc-wide-1024x505.png" alt="The relative source code sizes of GCC, CRuby, and the LLVM option." width="640" height="316" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/sloc-wide-1024x505.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/sloc-wide-300x148.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/sloc-wide-768x379.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/sloc-wide.png 1467w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-664837" class="wp-caption-text"&gt;Figure 1: CRuby’s source code size compared to GCC&amp;#8217;s and LLVM&amp;#8217;s source code size.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As for the machine code, GCC and LLVM binaries are much bigger, from 7 to 18 times bigger, as shown in Figure 2:&lt;/p&gt; &lt;div id="attachment_664817" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664817" class="wp-image-664817 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/objsize-wide-1024x566.png" alt="The relative machine code sizes of GCC, CRuby, and LLVM." width="640" height="354" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/objsize-wide-1024x566.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/objsize-wide-300x166.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/objsize-wide-768x425.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/objsize-wide.png 1307w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-664817" class="wp-caption-text"&gt;Figure 2: CRuby’s machine code is significantly smaller than GCC&amp;#8217;s and LLVM&amp;#8217;s machine code.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Imagine adding a JIT for a simple language with LLVM. You can easily increase its interpreter binary code size by a hundred times. CRuby with the current JIT requires much less memory than &lt;a href="https://www.jruby.org" target="_blank" rel="noopener noreferrer"&gt;JRuby&lt;/a&gt; or &lt;a href="https://github.com/oracle/truffleruby" target="_blank" rel="noopener noreferrer"&gt;Graal/TruffleRuby&lt;/a&gt;. Still, the large code size can be a serious problem for cloud, &lt;a href="https://en.wikipedia.org/wiki/Internet_of_things" target="_blank" rel="noopener noreferrer"&gt;IoT&lt;/a&gt;, or mobile environments.&lt;/p&gt; &lt;h3 id="disadvantages-of-gccllvm-based-jit"&gt;GCC/LLVM compilation speed&lt;/h3&gt; &lt;p&gt;Second, GCC/LLVM compilation speed is slow. It might feel like 20ms on a modern Intel CPU for a method compilation with GCC/LLVM is short, but for less powerful but widely used CPUs this value can be a half-second. For example, according to the &lt;a href="https://www.spec.org/cpu2000/CINT2000/176.gcc/docs/176.gcc.html" target="_blank" rel="noopener noreferrer"&gt;SPEC2000 176.gcc&lt;/a&gt; benchmark, the &lt;a href="https://en.wikipedia.org/wiki/Raspberry_Pi" target="_blank" rel="noopener noreferrer"&gt;Raspberry PI3 B3+&lt;/a&gt; CPU is about 30 times slower than the Intel i7-9700K (score 320 vs. 8520).&lt;/p&gt; &lt;p&gt;We need JIT even more on slow machines, but JIT compilation becomes intolerably slow for these. Even on fast machines, GCC/LLVM-based JITs can be too slow in environments like &lt;a href="https://en.wikipedia.org/wiki/MinGW" target="_blank" rel="noopener noreferrer"&gt;MinGW&lt;/a&gt;. Faster JIT speed can also help achieve desirable JIT performance through aggressive &lt;a href="https://en.wikipedia.org/wiki/Adaptive_optimization" target="_blank" rel="noopener noreferrer"&gt;adaptive optimization&lt;/a&gt; and &lt;a href="https://compileroptimizations.com/category/function_inlining.htm" target="_blank" rel="noopener noreferrer"&gt;function inlining&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;What might a faster JIT compilation look like? A keynote about the &lt;a href="https://youtu.be/Uqch1rjPls8" target="_blank" rel="noopener noreferrer"&gt;Java Falcon compiler&lt;/a&gt; at the 2017 LLVM developers conference suggested about 100ms per method for an LLVM-based JIT compiler and one millisecond for the faster &lt;a href="https://docs.oracle.com/javase/7/docs/technotes/guides/vm/performance-enhancements-7.html#tieredcompilation" target="_blank" rel="noopener noreferrer"&gt;tier-one JVM compiler&lt;/a&gt;. Answering a question about using LLVM for a Python JIT implementation, the speaker (Philip Reems) said that you first need a tier-one compiler implementation. With MJIT for Ruby, we went from the opposite direction by implementing a tier two compiler first.&lt;/p&gt; &lt;p&gt;So, why is GCC/LLVM compilation slow? Here is a full list of GCC-8 backend passes presented in their execution order, as shown in Figure 3:&lt;/p&gt; &lt;div id="attachment_664987" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664987" class="wp-image-664987 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/passes-1-1024x768.png" alt="" width="640" height="480" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/passes-1-1024x768.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/passes-1-300x225.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/passes-1-768x576.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-664987" class="wp-caption-text"&gt;Figure 3: GCC-8 backend passes presented in their execution order.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;There are 321 compiler passes and 239 of them are unique. This fact probably reflects that the GCC community has had more than 600 contributors. Some of these passes are repeated runs of the same optimizations (e.g., &lt;a href="https://en.wikipedia.org/wiki/Dead_code_elimination" target="_blank" rel="noopener noreferrer"&gt;dead code elimination&lt;/a&gt;). Many compiler passes traverse the &lt;a href="https://en.wikipedia.org/wiki/Intermediate_representation" target="_blank" rel="noopener noreferrer"&gt;intermediate representation&lt;/a&gt; (IR) more than once. For example, the &lt;a href="https://en.wikipedia.org/wiki/Register_allocation" target="_blank" rel="noopener noreferrer"&gt;register allocator&lt;/a&gt; traverses it at least eight times. Running all of these passes requires a lot of time. There are those who think that by switching off most of the passes we can speed up GCC/LLVM compilation proportionally. Unfortunately, this is not true.&lt;/p&gt; &lt;p&gt;The biggest problem for using GCC and LLVM in a lightweight JIT compiler is long initialization time. For small code, initialization can take a majority of the compilation time, and small-method code is a typical scenario for Ruby and other programs in other &lt;a href="https://en.wikipedia.org/wiki/Dynamic_programming_language" target="_blank" rel="noopener noreferrer"&gt;dynamic&lt;/a&gt; high-level languages.&lt;/p&gt; &lt;p&gt;The following diagram illustrates the long startup time of GCC-8/LLVM-8 on an Intel i7-9700K under &lt;a href="https://start.fedoraproject.org" target="_blank" rel="noopener noreferrer"&gt;Fedora Core&lt;/a&gt; 29, as shown in Figure 4:&lt;/p&gt; &lt;div id="attachment_664897" style="width: 625px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664897" class="wp-image-664897 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/startup.png" alt="GCC-8/LLVM-8 takes a long time to start up on an Intel i7-9700K under Fedora Core 29." width="615" height="460" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/startup.png 615w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/startup-300x224.png 300w" sizes="(max-width: 615px) 100vw, 615px" /&gt;&lt;p id="caption-attachment-664897" class="wp-caption-text"&gt;Figure 4: GCC-8/LLVM-8 startup time on an Intel i7-9700K under Fedora Core 29.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;So, you can not switch off optimizations and proportionally speed up GCC and Clang.&lt;/p&gt; &lt;h3 id="disadvantages-of-gccllvm-based-jit"&gt;Function inlining with GCC/LLVM&lt;/h3&gt; &lt;p&gt;Function inlining is the most important optimization for better JIT performance. Method calls are expensive and inlining permits optimizations in a bigger scope.&lt;/p&gt; &lt;p&gt;When both are written in Ruby, inlining one method into another one is a not a problem. We can do this on the VM instruction level or when we generate machine code. The problem is inlining a method written on C into a method written on Ruby or vice versa.&lt;/p&gt; &lt;p&gt;Here is a small example:&lt;/p&gt; &lt;pre&gt; x = 2 10.times {x *= 2}&lt;/pre&gt; &lt;p&gt;Ruby code interpreted by the CRuby &lt;a href="https://en.wikipedia.org/wiki/Virtual_machine" target="_blank" rel="noopener noreferrer"&gt;VM&lt;/a&gt; calls the method &lt;code&gt;times&lt;/code&gt;, which is implemented in C. This C code repeatedly calls another Ruby method interpreted by the VM and implementing a multiplication operation, as shown in Figure 5:&lt;/p&gt; &lt;div id="attachment_664907" style="width: 590px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664907" class="wp-image-664907 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/times.png" alt="How the times method works with CRuby." width="580" height="170" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/times.png 580w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/times-300x88.png 300w" sizes="(max-width: 580px) 100vw, 580px" /&gt;&lt;p id="caption-attachment-664907" class="wp-caption-text"&gt;Figure 5: The &lt;code&gt;times&lt;/code&gt; method through CRuby.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;How can we integrate all three parts of the code into one generated function? Let us consider the current structure of MJIT, as shown in Figure 6:&lt;/p&gt; &lt;div id="attachment_664887" style="width: 638px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664887" class="wp-image-664887 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT-header.png" alt="MJIT's structure." width="628" height="335" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT-header.png 628w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT-header-300x160.png 300w" sizes="(max-width: 628px) 100vw, 628px" /&gt;&lt;p id="caption-attachment-664887" class="wp-caption-text"&gt;Figure 6: MJIT&amp;#8217;s structure.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;A C function that implements a standard Ruby method and can be inlined should be in the precompiled header. The more code we insert into the environment header, the slower the MJIT precompiled header generation, and thus the slower the MJIT startup. Another consequence is slower JIT code generation because of bigger precompiled header.&lt;/p&gt; &lt;p&gt;We could also rewrite C code in Ruby. Sometimes this could work, but in the majority of cases, doing so would result in slower generated code.&lt;/p&gt; &lt;h2 id="light-weight-jit-compiler"&gt;Lightweight JIT compiler&lt;/h2&gt; &lt;p&gt;After analyzing the current disadvantages of MJIT, I came to the conclusion that a lightweight JIT compiler could solve these issues. I think the lightweight JIT compiler should be either an addition to the existing MJIT compiler or the only JIT compiler in cases where the current one does not work.&lt;/p&gt; &lt;p&gt;There is another reason for the lightweight JIT compiler. I believe this compiler could be a good solution for MRuby JIT and would help to expand Ruby usage from a mostly server market to the mobile and IoT markets.&lt;/p&gt; &lt;p&gt;So, last year I started to work on a lightweight JIT compiler mostly in my spare time. Because I&amp;#8217;d like to use the JIT compiler not only for Ruby, I decided to make it a universal JIT compiler and a standalone project.&lt;/p&gt; &lt;h2&gt;MIR&lt;/h2&gt; &lt;p&gt;The central notion of JIT is a well-defined intermediate language called Medium Internal Representation, or MIR. You can find the name in &lt;a href="https://www.amazon.ca/Advanced-Compiler-Design-Implementation-Muchnick/dp/1558603204" target="_blank" rel="noopener noreferrer"&gt;Steven Muchnik&amp;#8217;s famous book &amp;#8220;Advanced Compiler Design and Implementation.&amp;#8221;&lt;/a&gt; The &lt;a href="https://www.rust-lang.org/" target="_blank" rel="noopener noreferrer"&gt;Rust&lt;/a&gt; team also uses this term for a Rust intermediate language. Still, I decided to use the same name because I like it: MIR means &amp;#8220;peace&amp;#8221; and &amp;#8220;world&amp;#8221; in Russian.&lt;/p&gt; &lt;p&gt;MIR is strongly typed and flexible enough. MIR in different forms is capable of representing machine code for both &lt;a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computer" target="_blank" rel="noopener noreferrer"&gt;CISC&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer" target="_blank" rel="noopener noreferrer"&gt;RISC&lt;/a&gt; processors. Although this lightweight JIT compiler is a standalone project, I am planning to try it first with CRuby or MRuby JIT.&lt;/p&gt; &lt;p&gt;To get a better understanding of MIR, let us consider the Eratosthenes prime sieve algorithm code as an example. Here is the C code for sieve:&lt;/p&gt; &lt;pre&gt;#define Size 819000 int sieve (int iter) { int i, k, prime, count, n; char flags[Size]; for (n = 0; n &amp;#60; iter; n++) { count = 0; for (i = 0; i &amp;#60; Size; i++) flags[i] = 1; for (i = 0; i &amp;#60; Size; i++) if (flags[i]) { prime = i + i + 3; for (k = i + prime; k &amp;#60; Size; k += prime) flags[k] = 0; count++; } } return count; }&lt;/pre&gt; &lt;p&gt;And here is the MIR textual representation for the same code. There are no hard registers in MIR, only typed variables. The &lt;a href="https://en.wikipedia.org/wiki/Calling_convention" target="_blank" rel="noopener noreferrer"&gt;calling convention&lt;/a&gt; is also hidden:&lt;/p&gt; &lt;pre&gt;m_sieve: module export sieve sieve: func i32, i32:iter local i64:flags, i64:count, i64:prime, i64:n, i64:i, i64:k, i64:temp alloca flags, 819000 mov n, 0 loop: bge fin, n, iter mov count, 0; mov i, 0 loop2: bgt fin2, i, 819000 mov ui8:(flags, i), 1; add i, i, 1 jmp loop2 fin2: mov i, 0 loop3: bgt fin3, i, 819000 beq cont3, ui8:(flags,i), 0 add temp, i, i; add prime, temp, 3; add k, i, prime loop4: bgt fin4, k, 819000 mov ui8:(flags, k), 0; add k, k, prime jmp loop4 fin4: add count, count, 1 cont3: add i, i, 1 jmp loop3 fin3: add n, n, 1; jmp loop fin: ret count endfunc endmodule&lt;/pre&gt; &lt;p&gt;The first operands in the &lt;code&gt;func&lt;/code&gt; pseudo-instruction are the function return types (a MIR function can return multiple values), and after that, all function arguments are declared. Local variables are declared as 64-bit integers through the &lt;em&gt;local&lt;/em&gt; pseudo-instruction.&lt;/p&gt; &lt;h2 id="light-weight-jit-compiler-project-goals"&gt;Lightweight JIT compiler project goals&lt;/h2&gt; &lt;p&gt;I set performance goals for the JIT compiler. Compared to GCC with -O2, this compiler should have 100 times faster compilation, 100 times faster start-up, and 100 times smaller code size. As for the generated code performance, I decided that it should be at least 70% of GCC -O2 performance.&lt;/p&gt; &lt;p&gt;The implementation should be simple too at less than 10K C lines, because I want wider adoption of this tool. Simple code is easier to learn and maintain. I&amp;#8217;d like also to avoid any external dependencies for this project. At the end of the article, you can see the actual results I have now.&lt;/p&gt; &lt;h3 id="how-to-achieve-the-performance-goals"&gt;How to achieve these performance goals&lt;/h3&gt; &lt;p&gt;Optimizing compilers are big and complex because they are trying to improve any code, including rare edge cases. Because they do a lot of things, compilation speed becomes important. These compilers use the fastest algorithms and data structures for compiled programs of different sizes, from small to huge ones, even if the algorithms and data structures are complicated.&lt;/p&gt; &lt;p&gt;So, to achieve our goals, we need to use a few of the most valuable optimizations, optimize only frequently occurring cases, and use algorithms with the best combination of simplicity and performance.&lt;/p&gt; &lt;p&gt;So what are the most valuable optimizations? The most important optimizations are those for effectively exploiting the most commonly used CPU resources: instructions and registers. Therefore, the most valuable optimizations are good register allocation (RA) and &lt;a href="https://en.wikipedia.org/wiki/Instruction_selection" target="_blank" rel="noopener noreferrer"&gt;instruction selection&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Recently, I did an experiment by switching on only a fast and simple RA and combiner in GCC. There are no options to do this, I needed to modify GCC. (I can provide a patch if somebody is interested.) Compared to hundreds of optimizations in GCC-9.0 with -O2, these two optimizations achieve almost 80% performance on an Intel i7-9700K machine under Fedora Core 29 for real-world programs through &lt;a href="https://www.spec.org/benchmarks.html#cpu" target="_blank" rel="noopener noreferrer"&gt;SpecCPU&lt;/a&gt;, one of the most credible compiler benchmark suites:&lt;/p&gt; &lt;table style="height: 90px;" width="608" align="center"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;SPECInt2000 Est.&lt;/th&gt; &lt;th&gt;GCC -O2&lt;/th&gt; &lt;th&gt;GCC -O0 + simple RA + combiner&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;-fno-inline&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;5458&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;4342 (80%)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;-finline&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;6141&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;4339 (71%)&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;You might ask, &amp;#8220;How is this possible? What do the other numerous optimizations do?&amp;#8221; Having worked for many years on optimizing compilers, I would like to take this opportunity to say how difficult it is to improve the performance of well-established optimizing compilers.&lt;/p&gt; &lt;h3 id="how-to-achieve-the-performance-goals"&gt;The reality of optimizing compiler performance&lt;/h3&gt; &lt;p&gt;In the integrated circuit world, there is &lt;a href="https://en.wikipedia.org/wiki/Moore%27s_law" target="_blank" rel="noopener noreferrer"&gt;Moore&amp;#8217;s law&lt;/a&gt;, which says that the number of transistors on the circuit doubles every 18 months.&lt;/p&gt; &lt;p&gt;In the optimizing compiler world, people like to mention &lt;a href="http://proebsting.cs.arizona.edu/law.html" target="_blank" rel="noopener noreferrer"&gt;Proebsting&amp;#8217;s law&lt;/a&gt; to show how hard it is to improve the performance of generated code. Proebsting&amp;#8217;s law says that optimizing compiler developers improve generated code performance by two times every 18 years.&lt;/p&gt; &lt;p&gt;Actually, this &amp;#8220;law&amp;#8221; is too optimistic, and I never saw that anyone tested this. (It is hard to check because you need to wait 18 years.) So, recently I checked it on SPEC CPU2000. SPEC CPU is one of the most credible benchmark suites used by optimizing compiler developers. It contains a set of CPU-intensive applications from the real world; for example, a specific version of GCC is one of the benchmarks. There are many versions of SPEC CPU: 2000, 2006, and 2017. I used the 2000 version because it does not require days to run it. I used the 17-year-old GCC-3.1 compiler (the first GCC version supporting AMD64) and the recent version GCC-8 in their peak performance modes on the same Intel i7-4790K processor:&lt;/p&gt; &lt;table style="height: 59px;" width="608" align="center"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;GCC 3.1 (-O3)&lt;/th&gt; &lt;th&gt;GCC 8 (-Ofast -flto -march=native)&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;SPECInt2000 w/o eon&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;4498&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;5212 (+16%)&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;The actual performance improvement is &lt;strong&gt;only 16%&lt;/strong&gt;, which is not close to the 100% Proebsting&amp;#8217;s law states.&lt;/p&gt; &lt;p&gt;Looking at the progress of optimizing compilers, people believe we should not spend our time on their development at all. Dr. Bernstein, an author of the &lt;a href="https://en.wikipedia.org/wiki/SipHash" target="_blank" rel="noopener noreferrer"&gt;SipHash&lt;/a&gt; algorithm used in CRuby, expressed this point of view in &lt;a href="https://cr.yp.to/talks/2015.04.16/slides-djb-20150416-a4.pdf" target="_blank" rel="noopener noreferrer"&gt;one of his talks&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;There is another point of view that we should still try to improve the performance of generated code. &lt;a href="https://www.theregister.co.uk/2013/08/16/it_electricity_use_worse_than_you_thought" target="_blank" rel="noopener noreferrer"&gt;By some estimates&lt;/a&gt;, in 2013 (before active cryptocurrency mining) computers consumed 10% of all produced electricity. Computer electricity consumption in the year 2040 &lt;a href="https://www.sciencealert.com/computers-will-require-more-energy-than-the-world-generates-by-2040" target="_blank" rel="noopener noreferrer"&gt;could easily equal the total electricity production from the year 2016&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;A one percent compiler performance improvement in &lt;a href="https://en.wikipedia.org/wiki/Energy_proportional_computing" target="_blank" rel="noopener noreferrer"&gt;energy-proportional computing&lt;/a&gt; (an IT industry goal) means saving 25 terawatt-hours (TWh) out of the &lt;a href="https://en.wikipedia.org/wiki/Electricity_generation" target="_blank" rel="noopener noreferrer"&gt;25,000 TWh annual world electricity production&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Twenty-five terawatt-hours is equal to the average annual electricity production of six &lt;a href="https://www.usbr.gov/lc/hooverdam/faqs/powerfaq.html" target="_blank" rel="noopener noreferrer"&gt;Hoover dams&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="the-current-state-of-mir-project"&gt;&lt;img class="alignnone size-full wp-image-664697" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/hooverdam.jpg" alt="" width="1200" height="797" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/hooverdam.jpg 1200w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/hooverdam-300x199.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/hooverdam-768x510.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/hooverdam-1024x680.jpg 1024w" sizes="(max-width: 1200px) 100vw, 1200px" /&gt;&lt;/h2&gt; &lt;p&gt;Although the optimizing compiler topic is interesting to me, let us return to the MIR project description.&lt;/p&gt; &lt;h2 id="the-current-state-of-mir-project"&gt;The current state of the MIR project&lt;/h2&gt; &lt;p&gt;Figure 7 shows a diagram detailing the current state of the MIR project:&lt;/p&gt; &lt;div id="attachment_664787" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664787" class="wp-image-664787 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir3-300x212.png" alt="Current MIR project diagram" width="300" height="212" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir3-300x212.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir3.png 680w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-664787" class="wp-caption-text"&gt;Figure 7: The current state of the MIR project.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Currently, I can create MIR through an API or from MIR textual or binary representation. The MIR binary representation is up to 10 times more compact and up to 10 times faster to read than the textual one.&lt;/p&gt; &lt;p&gt;I can interpret MIR code and generate AMD64 machine code in memory from MIR. Recently, I got rid of the only external dependency used by the MIR interpreter, the &lt;a href="https://sourceware.org/libffi" target="_blank" rel="noopener noreferrer"&gt;Libffi&lt;/a&gt; foreign function interface library.&lt;/p&gt; &lt;p&gt;I can generate C code from MIR, and I am working on a C-to-MIR compiler, which is about 90% done in my opinion.&lt;/p&gt; &lt;h2 id="possible-future-directions-of-mir-project"&gt;Possible future directions for the MIR project&lt;/h2&gt; &lt;p&gt;Figure 8 shows the possible development directions for this project:&lt;/p&gt; &lt;div id="attachment_664797" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664797" class="wp-image-664797 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mirall-300x190.png" alt="ossible future development directions for the MIR project." width="300" height="190" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mirall-300x190.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mirall.png 740w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-664797" class="wp-caption-text"&gt;Figure 8: Possible future development directions for the MIR project.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Generating MIR from &lt;a href="https://llvm.org/docs/LangRef.html" target="_blank" rel="noopener noreferrer"&gt;LLVM internal representation&lt;/a&gt; permits the use of code from different languages implemented with LLVM; for example, Rust or &lt;a href="https://crystal-lang.org" target="_blank" rel="noopener noreferrer"&gt;Crystal&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Generating MIR from &lt;a href="https://en.wikipedia.org/wiki/Java_bytecode" target="_blank" rel="noopener noreferrer"&gt;Java bytecode&lt;/a&gt; would allow the same for languages implemented with &lt;a href="https://en.wikipedia.org/wiki/Java_virtual_machine" target="_blank" rel="noopener noreferrer"&gt;JVM&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Generating &lt;a href="https://webassembly.org" target="_blank" rel="noopener noreferrer"&gt;WebAssembly&lt;/a&gt; from MIR could allow using MIR code in web browsers. Actually, MIR features are pretty close to these of WebAssembly. The only big difference is that WebAssembly is a stack-based internal representation, and MIR is a register-based one.&lt;/p&gt; &lt;p&gt;There will be many interesting possibilities if all the directions are implemented.&lt;/p&gt; &lt;h2 id="mir-generator"&gt;MIR generator&lt;/h2&gt; &lt;p&gt;Currently, the most interesting component, at least for me, is the MIR generator producing optimized machine code. Figure 9 shows how it works:&lt;/p&gt; &lt;div id="attachment_664807" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664807" class="wp-image-664807 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir-gen-300x146.png" alt="Flow chart for the MIR generator." width="300" height="146" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir-gen-300x146.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir-gen-768x375.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir-gen.png 820w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-664807" class="wp-caption-text"&gt;Figure 9: The process the MIR generator follows.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here is the process in more detail. First, we simplify MIR as much as possible, which means only using register indirect memory addressing. It also means that immediate instruction operands are used only in move instructions. During this pass, we also remove unused instructions through local value numbering.&lt;/p&gt; &lt;p&gt;Then, we inline function calls represented by the MIR instructions &lt;code&gt;inline&lt;/code&gt; and &lt;code&gt;call&lt;/code&gt;and, after that, build the &lt;a href="https://en.wikipedia.org/wiki/Control-flow_graph" target="_blank" rel="noopener noreferrer"&gt;control-flow graph&lt;/a&gt; (CFG)—in other words, the &lt;a href="https://en.wikipedia.org/wiki/Basic_block" target="_blank" rel="noopener noreferrer"&gt;basic blocks&lt;/a&gt; and edges between them. Next, we transform code to reuse already calculated values in global scope through so-called &lt;a href="https://en.wikipedia.org/wiki/Common_subexpression_elimination" target="_blank" rel="noopener noreferrer"&gt;global common subexpression elimination&lt;/a&gt; (GCSE). This step is an important optimization for inlined code.&lt;/p&gt; &lt;p&gt;The next pass mostly removes instructions found redundant on the previous pass through a dead code elimination optimization. Then, we do &lt;a href="https://en.wikipedia.org/wiki/Sparse_conditional_constant_propagation" target="_blank" rel="noopener noreferrer"&gt;sparse conditional constant propagation&lt;/a&gt; (SCCP). This step is also an important optimization for inlined code when there are constant call arguments. We also find that there can be constant expression values.&lt;/p&gt; &lt;p&gt;Constant values can switch off CFG paths during any execution. Switching off these paths can make other values constant, too. SCCP is a combined optimization, which means its result is better than performing the two separate optimizations of constant propagation and removing unused CFG paths.&lt;/p&gt; &lt;p&gt;After that, we run the machine-dependent code. Most x86 instructions, for example, additionally require the instruction result operand to be the same as one of the input operands. Therefore, the machine-dependent code is run to produce two-operand instructions. This code also generates additional MIR instructions for call parameter passing and returns.&lt;/p&gt; &lt;p&gt;The next step is to find &lt;a href="https://web.cs.wpi.edu/~kal/PLT/PLT8.6.4.html" target="_blank" rel="noopener noreferrer"&gt;natural loops&lt;/a&gt; in the MIR code CFG. This information will be used for the subsequent register allocation. Then, we calculate &lt;a href="https://en.wikipedia.org/wiki/Live_variable_analysis" target="_blank" rel="noopener noreferrer"&gt;live information&lt;/a&gt; for MIR variables. In the compiler world, this technique is known as a backward &lt;a href="https://en.wikipedia.org/wiki/Data-flow_analysis" target="_blank" rel="noopener noreferrer"&gt;data-flow problem&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Once that work is complete, we calculate program points where MIR variables live. This info is used in a fast register allocator that assigns target hard registers, or stack slots, to MIR variables and removes various copy instructions. After the register assignment, we rewrite the MIR code, changing variables to the assigned hard registers or stack slots.&lt;/p&gt; &lt;p&gt;Then, we try to combine pairs of data-dependent MIR instructions into ones whose forms can represent a machine instruction. This is an instruction selection task. This pass also does &lt;a href="https://en.wikipedia.org/wiki/Copy_propagation" target="_blank" rel="noopener noreferrer"&gt;copy propagation&lt;/a&gt; optimization.&lt;/p&gt; &lt;p&gt;After instruction combining, there are usually many instructions whose output is never used. We delete such instructions. And then, finally, we generate machine code in memory. Each MIR instruction is encoded by a machine instruction. For AMD64, the encoding can be complicated.&lt;/p&gt; &lt;h2 id="some-mir-generator-features"&gt;MIR generator features&lt;/h2&gt; &lt;p&gt;These days, most compiler optimizations are implemented for &lt;a href="https://en.wikipedia.org/wiki/Static_single_assignment_form" target="_blank" rel="noopener noreferrer"&gt;static single assignment form&lt;/a&gt;. This is a special form of IR where we have only one assignment to each variable in the function IR. It was invented by IBM researchers a long time ago.&lt;/p&gt; &lt;p&gt;Using SSA simplifies the optimization implementations, but building and destroying this form is expensive. Using SSA for the MIR generator&amp;#8217;s short-pass pipeline makes little sense to me, so I don&amp;#8217;t use it.&lt;/p&gt; &lt;p&gt;Also, I don&amp;#8217;t generate position-independent code. I don&amp;#8217;t see any reasons to do this now. Generating such code is more complicated and decreases performance. For the AMD Geode processor (used in one version of the laptop for the &lt;a href="https://en.wikipedia.org/wiki/One_Laptop_per_Child" target="_blank" rel="noopener noreferrer"&gt;One Laptop per Child initiative&lt;/a&gt;) the performance decrease achieved 7%. For modern processors, the performance decrease is much smaller but still exists.&lt;/p&gt; &lt;h2 id="possible-ways-to-compile-c-to-mir"&gt;Possible ways to compile C to MIR&lt;/h2&gt; &lt;p&gt;To start using MIR in CRuby, I need a C-to-MIR compiler. There are several ways to implement this feature. I could implement an LLVM IR-to-MIR compiler or write a GCC port targeting MIR, but doing this would create a big dependency on a particular external project. It is not an easy task either. Once, I worked in a team that specialized in porting GCC to new targets and the standard estimation was at least six months of work to create a simple &amp;#8220;hello, world&amp;#8221; program.&lt;/p&gt; &lt;p&gt;On the other hand, people have written small C compilers pretty quickly. Here, I can mention the &lt;a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler" target="_blank" rel="noopener noreferrer"&gt;Tiny C Compiler&lt;/a&gt;, and the recent &lt;a href="https://github.com/rui314/8cc" target="_blank" rel="noopener noreferrer"&gt;8cc&lt;/a&gt; and &lt;a href="https://github.com/rui314/9cc" target="_blank" rel="noopener noreferrer"&gt;9cc&lt;/a&gt; compiler projects.&lt;/p&gt; &lt;p&gt;So, I decided to write my own C-to-MIR compiler first. This compiler should implement standard C11 without optional features, such as variable arrays, complex numbers, and atomic data.&lt;/p&gt; &lt;p&gt;The major goal is simplicity, not speed. Again, doing this makes studying the code easier for other people and reduces the effort required to maintain it.&lt;/p&gt; &lt;h3 id="c-to-mir-compiler"&gt;C-to-MIR compiler&lt;/h3&gt; &lt;p&gt;Simplicity is usually achieved by dividing tasks into small, manageable subtasks. There is even an extreme &lt;a href="https://www.cs.indiana.edu/~dyb/pubs/nano-jfp.pdf" target="_blank" rel="noopener noreferrer"&gt;nanopass compiler design&lt;/a&gt; used for studying compiler topics in education.&lt;/p&gt; &lt;p&gt;My approach to the C compiler implementation is classic division on four passes of approximately the same size, as shown in Figure 10:&lt;/p&gt; &lt;div id="attachment_664777" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664777" class="wp-image-664777 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir2c-300x62.png" alt="Flow chart for the C-to-MIR compiler." width="300" height="62" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir2c-300x62.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir2c-768x160.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir2c.png 780w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-664777" class="wp-caption-text"&gt;Figure 10: The C-to-MIR compiler approach.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;I don&amp;#8217;t use any tools for the compiler, like YACC. Also, I don&amp;#8217;t modify the ANSI standard grammar, although it is &lt;a href="https://en.wikipedia.org/wiki/Ambiguous_grammar" target="_blank" rel="noopener noreferrer"&gt;ambiguous&lt;/a&gt;. I use a parsing expression grammar (&lt;a href="https://en.wikipedia.org/wiki/Parsing_expression_grammar" target="_blank" rel="noopener noreferrer"&gt;PEG&lt;/a&gt;) manual parser. It is a parser with moderate backtracking and it is simple and small but a bit slower than &lt;a href="https://en.wikipedia.org/wiki/Deterministic_parsing" target="_blank" rel="noopener noreferrer"&gt;deterministic parsers&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The MIR-to-C compiler is mostly implemented. It passes around 1,000 tests from different C test suites. Recently, I achieved an important milestone: a successful bootstrap. The new &lt;code&gt;c2m&lt;/code&gt; compiles its own sources and generates a MIR binary. The execution of this MIR binary processes &lt;code&gt;c2m&lt;/code&gt; sources again and generates another MIR binary, and the two MIR binary files are identical (option &lt;code&gt;-el&lt;/code&gt; of the &lt;code&gt;c2m&lt;/code&gt; invocation that follows means the execution of generated MIR code through lazy machine code generation):&lt;/p&gt; &lt;pre&gt; cc -O3 -fno-tree-sra -std=gnu11 -Dx86_64 -I. mir-gen.c c2mir.c c2mir-driver.c mir.c -ldl -o c2m ./c2m -Dx86_64 -I. mir-gen.c c2mir.c c2mir-driver.c mir.c -o 1.bmir ./c2m 1.bmir -el -Dx86_64 -I. mir-gen.c c2mir.c c2mir-driver.c mir.c -o 2.bmir&lt;/pre&gt; &lt;p&gt;Still, a lot of effort should be made to finish the missing obligatory C11 standard features (e.g., wide characters), achieve full call ABI compatibility, generate more efficient code for switches, and implement the GCC C extensions necessary for the CRuby JIT implementation.&lt;/p&gt; &lt;h3 id="llvm-ir-to-mir-compiler"&gt;LLVM IR-to-MIR compiler&lt;/h3&gt; &lt;p&gt;I am also working on an LLVM IR-to-MIR compiler. Currently, I am focusing on translating the LLVM IR produced by Clang from standard C code. Doing so will be useful when we want to generate more optimized MIR code and don&amp;#8217;t need a fast C compiler (e.g., when building a MIR-based JIT for a programming language).&lt;/p&gt; &lt;p&gt;The only missing part now is the translation of composite values, which are generated by Clang in rare cases when passing small structures in function calls or returning them from function calls. In the future, this translator could be extended to support code generated from other programming languages implemented with LLVM, such as Rust.&lt;/p&gt; &lt;p&gt;I hope that &lt;a href="https://llvm.org/devmtg/2019-10/" target="_blank" rel="noopener noreferrer"&gt;LLVM IR will stabilize in the near future&lt;/a&gt; and no extensive maintenance will be necessary.&lt;/p&gt; &lt;h2 id="possible-ways-to-use-mir-for-cruby-mjit"&gt;Possible ways to use MIR for CRuby MJIT&lt;/h2&gt; &lt;p&gt;So how do I plan to use the MIR project for CRuby? Figure 11 shows how the current MJIT works:&lt;/p&gt; &lt;div id="attachment_664847" style="width: 636px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664847" class="wp-image-664847 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT0.png" alt="Diagram showing how the current MJIT works." width="626" height="418" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT0.png 626w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT0-300x200.png 300w" sizes="(max-width: 626px) 100vw, 626px" /&gt;&lt;p id="caption-attachment-664847" class="wp-caption-text"&gt;Figure 11: How the current MJIT works.&lt;/p&gt;&lt;/div&gt; &lt;h3 id="mir-compiler-as-a-tier1-jit-compiler-in-cruby"&gt;MIR compiler as a tier-one JIT compiler in CRuby&lt;/h3&gt; &lt;p&gt;Figure 12 shows how the future MJIT would look after implementing a MIR-based JIT compiler as a tier-one compiler:&lt;/p&gt; &lt;div id="attachment_664857" style="width: 637px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664857" class="wp-image-664857 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT1.png" alt="How the future MJIT would look after implementing a MIR-based JIT compiler as a tier one compiler." width="627" height="481" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT1.png 627w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT1-300x230.png 300w" sizes="(max-width: 627px) 100vw, 627px" /&gt;&lt;p id="caption-attachment-664857" class="wp-caption-text"&gt;Figure 12: How the future MJIT would look after implementing a MIR-based JIT compiler as a tier-one compiler.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The blue parts show the new data-flow for MJIT. When building CRuby, we could generate MIR code for the standard Ruby methods written in C. We can load this MIR code as a MIR binary. This part could be done very quickly.&lt;/p&gt; &lt;p&gt;MJIT could create MIR code for a Ruby method through the MIR API. This MIR code could inline the already existing MIR code functions. The corresponding machine code can be generated by the MIR generator. This is a fast method, but we could also generate machine code by translating MIR into C and then using GCC or LLVM. This is a much slower method, but it permits us to use the full spectrum of GCC/LLVM optimizations, plus it permits efficient implementation of inlining C code into Ruby code and vice versa.&lt;/p&gt; &lt;h3 id="mir-compiler-as-a-single-jit-compiler-in-cruby"&gt;MIR compiler as a single JIT compiler in CRuby&lt;/h3&gt; &lt;p&gt;For some environments, the MIR JIT compiler could be used as a single JIT compiler. In this case, MIR with MJIT would look as you see in Figure 13:&lt;/p&gt; &lt;div id="attachment_664867" style="width: 637px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664867" class="wp-image-664867 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT2.png" alt="Diagram showing how the MIR compiler would work as a single JIT compiler in CRuby." width="627" height="481" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT2.png 627w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT2-300x230.png 300w" sizes="(max-width: 627px) 100vw, 627px" /&gt;&lt;p id="caption-attachment-664867" class="wp-caption-text"&gt;Figure 13: How the MIR compiler would work as a single JIT compiler in CRuby.&lt;/p&gt;&lt;/div&gt; &lt;h3 id="mir-compiler-and-c-to-mir-compiler-as-a-single-jit-compiler-in-cruby"&gt;MIR compiler and C-to-MIR compiler as a single JIT compiler in CRuby&lt;/h3&gt; &lt;p&gt;Instead of directly generating MIR for the JIT compiler, we could generate C code first and translate it into MIR with the C-to-MIR translator. In this case, MJIT would look as you see in Figure 14:&lt;/p&gt; &lt;div id="attachment_664877" style="width: 637px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664877" class="wp-image-664877 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT3.png" alt="Diagram showing how the MIR compiler combined with the C-to-MIR compiler would work in CRuby." width="627" height="481" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT3.png 627w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT3-300x230.png 300w" sizes="(max-width: 627px) 100vw, 627px" /&gt;&lt;p id="caption-attachment-664877" class="wp-caption-text"&gt;Figure 14: How the MIR compiler combined with the C-to-MIR compiler would work in CRuby.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;I discussed the lightweight JIT compiler project with a few people, and two of them independently wanted to generate C code for JIT. It would make their life easier to use a MIR-based JIT compiler for their own JIT implementations.&lt;/p&gt; &lt;p&gt;The C-to-MIR JIT compiler is pretty small, has a fast startup, and can be used as a library to read the generated C code from memory. Although the C-to-MIR translator was not designed to be fast, it is still about 15 times faster than GCC with -O2. All of this makes such an approach viable.&lt;/p&gt; &lt;h2 id="current-performance-results"&gt;Current performance results&lt;/h2&gt; &lt;p&gt;And finally, here are the current performance results for the MIR generator and interpreter compared to GCC-8.2.1. I used the sieve benchmark on an Intel i7-9700K machine running Fedora Core 29. The sieve C code has no include directives and is only about 30 preprocessed lines:&lt;/p&gt; &lt;table align="center"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;MIR-gen&lt;/th&gt; &lt;th&gt;MIR-interp&lt;/th&gt; &lt;th&gt;gcc -O2&lt;/th&gt; &lt;th&gt;gcc -O0&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;compilation [1]&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.0&lt;/strong&gt; (75us)&lt;/td&gt; &lt;td&gt;0.16 (12us)&lt;/td&gt; &lt;td&gt;&lt;strong&gt;178&lt;/strong&gt; (13.35ms)&lt;/td&gt; &lt;td&gt;171 (12.8ms)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;execution [2]&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.0&lt;/strong&gt; (3.1s)&lt;/td&gt; &lt;td&gt;5.9 (18.3s)&lt;/td&gt; &lt;td&gt;&lt;strong&gt;0.94&lt;/strong&gt; (2.9s)&lt;/td&gt; &lt;td&gt;2.05 (6.34s)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;code size [3]&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.0&lt;/strong&gt; (175KB)&lt;/td&gt; &lt;td&gt;0.65 (114KB)&lt;/td&gt; &lt;td&gt;&lt;strong&gt;144&lt;/strong&gt; (25.2MB)&lt;/td&gt; &lt;td&gt;144 (25.2MB)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;startup [4]&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.0&lt;/strong&gt; (1.3us)&lt;/td&gt; &lt;td&gt;1.0 (1.3us)&lt;/td&gt; &lt;td&gt;&lt;strong&gt;9310&lt;/strong&gt; (12.1ms)&lt;/td&gt; &lt;td&gt;9850 (12.8ms)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;LOC [5]&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.0&lt;/strong&gt; (16K)&lt;/td&gt; &lt;td&gt;0.56 (9K)&lt;/td&gt; &lt;td&gt;&lt;strong&gt;93&lt;/strong&gt; (1480K)&lt;/td&gt; &lt;td&gt;93 (1480K)&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;The compilation speed of the MIR-generator is about 180 times faster than GCC with -O2. It takes 80 microseconds to generate the code for the sieve. And the sieve code generated by the MIR generator is only 6% slower.&lt;/p&gt; &lt;p&gt;The MIR generator&amp;#8217;s object size is much smaller than the object size of &lt;code&gt;cc1&lt;/code&gt;. MIR generator has a fast startup time and is suitable for use as a tier1 JIT compiler.&lt;/p&gt; &lt;p&gt;Here are the notes for each table row:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;[1]: Wall time of compilation of sieve code (without any include file and with using the memory file system for GCC).&lt;/li&gt; &lt;li&gt;[2]: The best wall time of 10 runs.&lt;/li&gt; &lt;li&gt;[3]: The stripped sizes of &lt;code&gt;cc1&lt;/code&gt; for GCC, and the MIR core and interpreter or generator for MIR.&lt;/li&gt; &lt;li&gt;[4]: Wall time of object code generation for an empty C file, or of the generation of an empty MIR module through the API.&lt;/li&gt; &lt;li&gt;[5]: Based only on the files required for the AMD64 C compiler and the minimal number of files required to create and run MIR code.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="current-mir-sloc-distribution"&gt;Current MIR SLOC distribution&lt;/h2&gt; &lt;p&gt;Figure 15 shows a source line distribution for the current version of the MIR project. The MIR-to-C compiler is about 12 thousand lines of C code. MIR core is about nine thousand lines:&lt;/p&gt; &lt;div id="attachment_664947" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664947" class="wp-image-664947 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/size-chart-1-300x225.png" alt="A source line distribution for the current version of the MIR project." width="300" height="225" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/size-chart-1-300x225.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/size-chart-1.png 756w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-664947" class="wp-caption-text"&gt;Figure 15: A source line distribution for the current version of the MIR project.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The MIR generator is less than five thousand lines.&lt;/p&gt; &lt;p&gt;Machine-dependent code used by the generator is about two thousand lines, so you can estimate the effort required to port the MIR generator to another target. For example, I expect that porting MIR to &lt;a href="https://en.wikipedia.org/wiki/ARM_architecture#AArch64" target="_blank" rel="noopener noreferrer"&gt;Aarch64&lt;/a&gt; will take me about one to two months of work.&lt;/p&gt; &lt;h2 id="competitors-of-the-mir-project"&gt;MIR project competitors&lt;/h2&gt; &lt;p&gt;I&amp;#8217;ve been studying JITs for a long time. Before starting the MIR project, I thought about adapting the existing code. Here is a comparison of MIR with the simple compiler projects I considered:&lt;/p&gt; &lt;table align="center"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Project&lt;/th&gt; &lt;th&gt;SLOC&lt;/th&gt; &lt;th&gt;License&lt;/th&gt; &lt;th&gt;IR type&lt;/th&gt; &lt;th&gt;Major Optimizations&lt;/th&gt; &lt;th&gt;Output&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;MIR&lt;/td&gt; &lt;td&gt;16K C&lt;/td&gt; &lt;td&gt;MIT&lt;/td&gt; &lt;td&gt;non-SSA&lt;/td&gt; &lt;td&gt;Inlining, GCSE, SCCP, RA, CP, DCE, LA&lt;/td&gt; &lt;td&gt;Binary code&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;DotGNU LibJIT&lt;/td&gt; &lt;td&gt;80K C&lt;/td&gt; &lt;td&gt;LGPL&lt;/td&gt; &lt;td&gt;non-SSA&lt;/td&gt; &lt;td&gt;Only RA and primitive CP&lt;/td&gt; &lt;td&gt;Binary code&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;.NET RyuJIT&lt;/td&gt; &lt;td&gt;360K C++&lt;/td&gt; &lt;td&gt;MIT&lt;/td&gt; &lt;td&gt;SSA&lt;/td&gt; &lt;td&gt;MIR ones minus SCCP plus LICM, Range&lt;/td&gt; &lt;td&gt;Binary code&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;QBE&lt;/td&gt; &lt;td&gt;10K C&lt;/td&gt; &lt;td&gt;MIT&lt;/td&gt; &lt;td&gt;SSA&lt;/td&gt; &lt;td&gt;MIR ones plus aliasing minus inlining&lt;/td&gt; &lt;td&gt;Assembler&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;LIBFirm&lt;/td&gt; &lt;td&gt;140K C&lt;/td&gt; &lt;td&gt;LGPL2&lt;/td&gt; &lt;td&gt;SSA&lt;/td&gt; &lt;td&gt;RA, Inlining, DCE, LICM, CP, LA, Others&lt;/td&gt; &lt;td&gt;Assembler&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;CraneLift&lt;/td&gt; &lt;td&gt;70K Rust&lt;/td&gt; &lt;td&gt;Apache&lt;/td&gt; &lt;td&gt;SSA&lt;/td&gt; &lt;td&gt;DCE, LICM, RA, GVN, CP, LA&lt;/td&gt; &lt;td&gt;Binary Code&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Here are the abbreviations used in the table:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;CP: &lt;a href="https://en.wikipedia.org/wiki/Copy_propagation" target="_blank" rel="noopener noreferrer"&gt;Copy propagation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;DCE: &lt;a href="https://en.wikipedia.org/wiki/Dead_code_elimination" target="_blank" rel="noopener noreferrer"&gt;Dead code elimination&lt;/a&gt;&lt;/li&gt; &lt;li&gt;GCSE: &lt;a href="https://en.wikipedia.org/wiki/Common_subexpression_elimination" target="_blank" rel="noopener noreferrer"&gt;Global common sub-expression elimination&lt;/a&gt;&lt;/li&gt; &lt;li&gt;GVN: &lt;a href="https://en.wikipedia.org/wiki/Value_numbering" target="_blank" rel="noopener noreferrer"&gt;Global value numbering&lt;/a&gt;&lt;/li&gt; &lt;li&gt;LA: Finding loops in CFG&lt;/li&gt; &lt;li&gt;LICM: &lt;a href="https://en.wikipedia.org/wiki/Loop-invariant_code_motion" target="_blank" rel="noopener noreferrer"&gt;Loop invariant code motion&lt;/a&gt;&lt;/li&gt; &lt;li&gt;RA: &lt;a href="https://en.wikipedia.org/wiki/Register_allocation" target="_blank" rel="noopener noreferrer"&gt;Register allocation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Range: &lt;a href="https://en.wikipedia.org/wiki/Value_range_analysis" target="_blank" rel="noopener noreferrer"&gt;Range analysis&lt;/a&gt;&lt;/li&gt; &lt;li&gt;SCCP: &lt;a href="https://en.wikipedia.org/wiki/Sparse_conditional_constant_propagation" target="_blank" rel="noopener noreferrer"&gt;Sparse conditional constant propagation&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Others include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Partial_redundancy_elimination" target="_blank" rel="noopener noreferrer"&gt;Partial redundancy elimination&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Loop_unrolling" target="_blank" rel="noopener noreferrer"&gt;Loop unrolling&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Scalar replacement&lt;/li&gt; &lt;li&gt;&lt;a href="https://stackoverflow.com/questions/1240539/what-is-tail-recursion-elimination" target="_blank" rel="noopener noreferrer"&gt;Tail recursion elimination&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Expression reassociation&lt;/li&gt; &lt;li&gt;Function cloning&lt;/li&gt; &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Strength_reduction" target="_blank" rel="noopener noreferrer"&gt;Strength reduction&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Loop_optimization" target="_blank" rel="noopener noreferrer"&gt;Loop optimizations&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Load store motion&lt;/li&gt; &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Jump_threading" target="_blank" rel="noopener noreferrer"&gt;Jump threading&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;After studying these projects closely, I decided to start the MIR project. The biggest cons of the existing projects were their size, the fact that it would be hard for me to achieve my goals using them, and that I can not control the projects. Also, the smaller source size of the MIR project makes studying the code easier for other people and reduces the effort required to maintain it.&lt;/p&gt; &lt;h2 id="plans-for-mir-project"&gt;Plans for the MIR project&lt;/h2&gt; &lt;p&gt;The MIR project is pretty ambitious. I&amp;#8217;ve decided to develop it in an open way because this permits me to receive valuable feedback from many people in the project&amp;#8217;s early stages. You can follow the progress of the project on &lt;a href="https://github.com/vnmakarov/mir" target="_blank" rel="noopener noreferrer"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Although MIR is still in the early stages of development, I plan to start using it for a CRuby/MRuby JIT implementation soon. It would be a useful way to improve the MIR compiler implementation and find missing features.&lt;/p&gt; &lt;p&gt;If the use of a MIR-based compiler for Ruby JIT is successful, I will work on the first release of the MIR project code, which I hope will be useful for JIT implementations of other programming languages.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#038;title=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" data-a2a-url="https://developers.redhat.com/blog/2020/01/20/mir-a-lightweight-jit-compiler-project/" data-a2a-title="MIR: A lightweight JIT compiler project"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/20/mir-a-lightweight-jit-compiler-project/"&gt;MIR: A lightweight JIT compiler project&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PDvpKffeLA8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;For the past three years, I&amp;#8217;ve been participating in adding just-in-time compilation (JIT) to CRuby. Now, CRuby has the method-based just-in-time compiler (MJIT), which improves performance for non-input/output-bound programs. The most popular approach to implementing a JIT is to use LLVM or GCC JIT interfaces, like ORC or LibGCCJIT. GCC and LLVM developers spend huge effort to implement the optimizations reliably, effectively, and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/20/mir-a-lightweight-jit-compiler-project/"&gt;MIR: A lightweight JIT compiler project&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">664687</post-id><dc:creator>Vladimir Makarov</dc:creator><dc:date>2020-01-20T08:00:32Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/20/mir-a-lightweight-jit-compiler-project/</feedburner:origLink></entry><entry><title>Integrating with SaaS Applications - An Introduction</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/G6YY4CZ7n00/integrating-saas-applications-an-introduction.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Architecture Blueprints" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-integrating_with_saas_applications_an_introduction</id><updated>2020-01-20T10:15:34Z</updated><published>2020-01-20T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: left; text-align: left;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-qp_02SNmfZ0/XiBjeEC3RjI/AAAAAAAAw3M/T-gLUnyTGL8ICEYby1mxjdK9u0GkttqBQCNcBGAsYHQ/s1600/LD-omnichannel-customer-experience.png" style="margin-left: auto; margin-right: auto;"&gt;&lt;img alt="integrate with saas applications" border="0" data-original-height="821" data-original-width="1600" height="164" src="https://1.bp.blogspot.com/-qp_02SNmfZ0/XiBjeEC3RjI/AAAAAAAAw3M/T-gLUnyTGL8ICEYby1mxjdK9u0GkttqBQCNcBGAsYHQ/s320/LD-omnichannel-customer-experience.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Part 1 - An introduction&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;Since introducing the &lt;a href="http://www.schabell.org/2018/11/integration-key-to-customer-experience-introduction.html" target="_blank"&gt;first architecture blueprint focused on omnichannel integration&lt;/a&gt;, we've been looking at how to integrate with Software as a Service (SaaS) applications.&lt;br /&gt;&lt;br /&gt;It's an interesting challenge in that we've been given the mission of creating of architectural content based on common customer adoption patterns. That's very different from most of the traditional marketing activities usually associated with generating content for the sole purpose of positioning products for solutions. When you're basing the content on actual execution in solution delivery, you're cutting out the &lt;i&gt;chuff.&amp;nbsp;&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;What's that mean?&lt;br /&gt;&lt;br /&gt;It means that it's going to provide you with a way to implement a solution using open source technologies by focusing on the integrations, structures and interactions that actually have been proven to work. What's not included are any vendor promises that you'll find in normal marketing content. Those promised that when it gets down to implementation crunch time, might not fully deliver on their promises.&lt;br /&gt;&lt;br /&gt;Enter the term &lt;i&gt;Architectural Blueprint.&amp;nbsp;&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;Let's look at these blueprints, how their created and what value they provide for your solution designs.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;&lt;a href="https://1.bp.blogspot.com/-SM3qwlfrFJA/XiV9iP-13NI/AAAAAAAAw30/gU7-wG0gmx4uDBmEnct1rzEQPpoyjDGUgCNcBGAsYHQ/s1600/Screenshot%2B2020-01-20%2Bat%2B11.14.08.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="integrate with saas applications" border="0" data-original-height="988" data-original-width="1565" height="202" src="https://1.bp.blogspot.com/-SM3qwlfrFJA/XiV9iP-13NI/AAAAAAAAw30/gU7-wG0gmx4uDBmEnct1rzEQPpoyjDGUgCNcBGAsYHQ/s320/Screenshot%2B2020-01-20%2Bat%2B11.14.08.png" title="" width="320" /&gt;&lt;/a&gt;The process&lt;/h3&gt;&lt;div&gt;The first step is to define what we are focusing on when we talk about integrating SaaS applications.&lt;br /&gt;&lt;br /&gt;We've settled on the following to guide our blueprint: &lt;i&gt;'Integrating with SaaS applications means providing your organization with consistent, responsive, and secure access to services, applications, and platforms.'&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;This is the launching principle that guides our research into how customers are looking at integrating with their SaaS application landscapes.&lt;i&gt;&amp;nbsp;&lt;/i&gt; &lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The approach taken is to research our existing customers that have implemented solutions in this space, collect their public facing content, research the internal implementation documentation collections from their successful engagements, and where necessary reach out to the field resources involved.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;What's next&lt;/h3&gt;The resulting content targets the following three items.&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;A slide deck of the architectural blueprint for use telling the portfolio solution story.&lt;/li&gt;&lt;li&gt;A generic architectural diagram providing the general details for the portfolio solution.&lt;/li&gt;&lt;li&gt;A write-up of the portfolio solution in a solution brief format.&lt;/li&gt;&lt;/ul&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;An overview of the series on integrating SaaS applications portfolio architecture blueprint can be found here:&lt;br /&gt;&lt;ol style="text-align: left;"&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/01/integrating-saas-applications-an-introduction.html" target="_blank"&gt;An introduction&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Common architectural elements&lt;/li&gt;&lt;li&gt;Example external CRM integration&lt;/li&gt;&lt;li&gt;Example 3rd-party platform integration&lt;/li&gt;&lt;li&gt;Example processes with 3rd-party platform integration&lt;/li&gt;&lt;/ol&gt;Catch up on any articles you missed by following one of the links above.&lt;br /&gt;&lt;br /&gt;Next in this series, taking a look at the generic common architecture to integrate SaaS applications. &lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=2_mGHutJiZ4:uRXOIwWBWSg:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=2_mGHutJiZ4:uRXOIwWBWSg:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=2_mGHutJiZ4:uRXOIwWBWSg:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=2_mGHutJiZ4:uRXOIwWBWSg:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=2_mGHutJiZ4:uRXOIwWBWSg:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=2_mGHutJiZ4:uRXOIwWBWSg:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=2_mGHutJiZ4:uRXOIwWBWSg:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=2_mGHutJiZ4:uRXOIwWBWSg:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=2_mGHutJiZ4:uRXOIwWBWSg:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=2_mGHutJiZ4:uRXOIwWBWSg:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=2_mGHutJiZ4:uRXOIwWBWSg:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/2_mGHutJiZ4" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/G6YY4CZ7n00" height="1" width="1" alt=""/&gt;</content><summary>Part 1 - An introductionSince introducing the first architecture blueprint focused on omnichannel integration, we've been looking at how to integrate with Software as a Service (SaaS) applications. It's an interesting challenge in that we've been given the mission of creating of architectural content based on common customer adoption patterns. That's very different from most of the traditional mar...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-01-20T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/2_mGHutJiZ4/integrating-saas-applications-an-introduction.html</feedburner:origLink></entry></feed>
